#!/usr/bin/env python3
import asyncio
import json
import logging
import os
from typing import Any, Dict, List, Optional, Union

from mcp.server.fastmcp import FastMCP
from mcp.types import TextContent

from .utils.validators import validate_ticker, validate_market_cap, validate_earnings_date, validate_price_range, validate_sector, validate_volume, validate_screening_params, validate_data_fields
from .utils.formatters import format_large_number
from .finviz_client.base import FinvizClient
from .finviz_client.screener import FinvizScreener
from .finviz_client.news import FinvizNewsClient
from .finviz_client.sector_analysis import FinvizSectorAnalysisClient
from .finviz_client.sec_filings import FinvizSECFilingsClient
# from .finviz_client.edgar_client import EdgarAPIClient  # Disabled due to missing dependency

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize MCP Server
server = FastMCP("Finviz MCP Server")

# Initialize Finviz clients
finviz_api_key = os.getenv('FINVIZ_API_KEY')
finviz_client = FinvizClient(api_key=finviz_api_key)
finviz_screener = FinvizScreener(api_key=finviz_api_key)
finviz_news = FinvizNewsClient(api_key=finviz_api_key)
finviz_sector = FinvizSectorAnalysisClient(api_key=finviz_api_key)
finviz_sec = FinvizSECFilingsClient(api_key=finviz_api_key)

# Initialize EDGAR API client
# edgar_client = EdgarAPIClient()  # Disabled due to missing dependency

# Create stub for EDGAR client when disabled
class EdgarClientStub:
    def get_filing_document_content(self, *args, **kwargs):
        return {"status": "error", "error": "EDGAR API client is disabled due to missing dependencies"}
    
    def get_multiple_filing_contents(self, *args, **kwargs):
        return []
    
    def get_company_filings(self, *args, **kwargs):
        return []
    
    def _get_cik_from_ticker(self, *args, **kwargs):
        return None
    
    def get_company_concept(self, *args, **kwargs):
        return {"error": "EDGAR API client is disabled due to missing dependencies"}
    
    @property
    def client(self):
        class StubClient:
            def get_company_facts(self, *args, **kwargs):
                return None
        return StubClient()

edgar_client = EdgarClientStub()

@server.tool()
def earnings_screener(
    earnings_date: str,
    market_cap: Optional[str] = None,
    min_price: Optional[Union[int, float, str]] = None,
    max_price: Optional[Union[int, float, str]] = None,
    min_volume: Optional[Union[int, str]] = None,
    sectors: Optional[List[str]] = None,
    premarket_price_change: Optional[Dict[str, Any]] = None,
    afterhours_price_change: Optional[Dict[str, Any]] = None
) -> List[TextContent]:
    """
    æ±ºç®—ç™ºè¡¨äºˆå®šéŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    
    Args:
        earnings_date: æ±ºç®—ç™ºè¡¨æ—¥ã®æŒ‡å®š (today_after, tomorrow_before, this_week, within_2_weeks)
        market_cap: æ™‚ä¾¡ç·é¡ãƒ•ã‚£ãƒ«ã‚¿ (small, mid, large, mega)
        min_price: æœ€ä½æ ªä¾¡
        max_price: æœ€é«˜æ ªä¾¡
        min_volume: æœ€ä½å‡ºæ¥é«˜
        sectors: å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼
        premarket_price_change: å¯„ã‚Šä»˜ãå‰ä¾¡æ ¼å¤‰å‹•ãƒ•ã‚£ãƒ«ã‚¿
        afterhours_price_change: æ™‚é–“å¤–ä¾¡æ ¼å¤‰å‹•ãƒ•ã‚£ãƒ«ã‚¿
    """
    try:
        # Validate parameters
        if not validate_earnings_date(earnings_date):
            raise ValueError(f"Invalid earnings_date: {earnings_date}")
        
        if market_cap is not None and not validate_market_cap(market_cap):
            raise ValueError(f"Invalid market_cap: {market_cap}")
        
        if not validate_price_range(min_price, max_price):
            raise ValueError("Invalid price range")
        
        if min_volume is not None and not validate_volume(min_volume):
            raise ValueError(f"Invalid min_volume: {min_volume}")
        
        if sectors:
            for sector in sectors:
                if not validate_sector(sector):
                    raise ValueError(f"Invalid sector: {sector}")
        
        # Prepare parameters
        params = {
            'earnings_date': earnings_date,
            'market_cap': market_cap,
            'min_price': min_price,
            'max_price': max_price,
            'min_volume': min_volume,
            'sectors': sectors or [],
            'premarket_price_change': premarket_price_change,
            'afterhours_price_change': afterhours_price_change
        }
        
        results = finviz_screener.earnings_screener(**params)
        
        if not results:
            return [TextContent(type="text", text="No stocks found matching the criteria.")]
        
        output_lines = [
            f"Earnings Screening Results ({len(results)} stocks found):",
            "=" * 60,
            "",
            "Default Screening Conditions Applied:",
            "- Market Cap: Small and above ($300M+)",
            "- Earnings Date: Yesterday after-hours OR today before-market",
            "- EPS Revision: Positive (upward revision)",
            "- Average Volume: 200,000+",
            "- Price: $10+",
            "- Price Trend: Positive change",
            "- 4-Week Performance: 0% to negative (recovery candidates)",
            "- Volatility: 1x and above",
            "- Stocks Only: ETFs excluded",
            "- Sort: EPS Surprise (descending)",
            "",
            "=" * 60,
            ""
        ]
        
        for stock in results:
            output_lines.extend([
                f"Ticker: {stock.ticker}",
                f"Company: {stock.company_name}",
                f"Sector: {stock.sector}",
                f"Price: ${stock.price:.2f}" if stock.price else "Price: N/A",
                f"Change: {stock.price_change:.2f}%" if stock.price_change else "Change: N/A",
                f"EPS Surprise: {stock.eps_surprise:.2f}%" if stock.eps_surprise else "EPS Surprise: N/A",
                f"Revenue Surprise: {stock.revenue_surprise:.2f}%" if stock.revenue_surprise else "Revenue Surprise: N/A",
                f"Volatility: {stock.volatility:.2f}" if stock.volatility else "Volatility: N/A",
                f"1M Performance: {stock.performance_1m:.2f}%" if stock.performance_1m else "1M Performance: N/A",
                "-" * 40,
                ""
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in earnings_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def volume_surge_screener() -> List[TextContent]:
    """
    å‡ºæ¥é«˜æ€¥å¢—ã‚’ä¼´ã†ä¸Šæ˜‡éŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå›ºå®šæ¡ä»¶ï¼‰
    
    å›ºå®šãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ï¼ˆå¤‰æ›´ä¸å¯ï¼‰ï¼š
    f=cap_smallover,ind_stocksonly,sh_avgvol_o100,sh_price_o10,sh_relvol_o1.5,ta_change_u2,ta_sma200_pa&ft=4&o=-change
    
    - æ™‚ä¾¡ç·é¡ï¼šã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Š ($300M+)
    - æ ªå¼ã®ã¿ï¼šETFé™¤å¤–
    - å¹³å‡å‡ºæ¥é«˜ï¼š100,000ä»¥ä¸Š
    - æ ªä¾¡ï¼š$10ä»¥ä¸Š
    - ç›¸å¯¾å‡ºæ¥é«˜ï¼š1.5å€ä»¥ä¸Š
    - ä¾¡æ ¼å¤‰å‹•ï¼š2%ä»¥ä¸Šä¸Šæ˜‡
    - 200æ—¥ç§»å‹•å¹³å‡ç·šä¸Š
    - ä¾¡æ ¼å¤‰å‹•é™é †ã‚½ãƒ¼ãƒˆ
    - å…¨ä»¶å–å¾—ï¼ˆåˆ¶é™ãªã—ï¼‰
    
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãªã— - å…¨ã¦ã®æ¡ä»¶ã¯å›ºå®šã•ã‚Œã¦ã„ã¾ã™
    """
    try:
        # å›ºå®šæ¡ä»¶ã§å®Ÿè¡Œï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãªã—ï¼‰
        results = finviz_screener.volume_surge_screener()
        
        if not results:
            return [TextContent(type="text", text="æŒ‡å®šã•ã‚ŒãŸå›ºå®šæ¡ä»¶ã§å‡ºæ¥é«˜æ€¥å¢—éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # å›ºå®šæ¡ä»¶ã®è¡¨ç¤º
        fixed_conditions = [
            "å›ºå®šãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶:",
            "- æ™‚ä¾¡ç·é¡: ã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Š ($300M+)",
            "- æ ªå¼ã®ã¿: ETFé™¤å¤–",
            "- å¹³å‡å‡ºæ¥é«˜: 100,000ä»¥ä¸Š",
            "- æ ªä¾¡: $10ä»¥ä¸Š",
            "- ç›¸å¯¾å‡ºæ¥é«˜: 1.5å€ä»¥ä¸Š",
            "- ä¾¡æ ¼å¤‰å‹•: 2%ä»¥ä¸Šä¸Šæ˜‡",
            "- 200æ—¥ç§»å‹•å¹³å‡ç·šä¸Š",
            "- ä¾¡æ ¼å¤‰å‹•é™é †ã‚½ãƒ¼ãƒˆ",
            "- å…¨ä»¶å–å¾—ï¼ˆåˆ¶é™ãªã—ï¼‰"
        ]
        
        # ç°¡æ½”ãªå‡ºåŠ›å½¢å¼ï¼ˆãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ã¿ï¼‰
        output_lines = [
            f"å‡ºæ¥é«˜æ€¥å¢—ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœ ({len(results)}éŠ˜æŸ„ç™ºè¦‹):",
            "=" * 60,
            ""
        ] + fixed_conditions + ["", "æ¤œå‡ºã•ã‚ŒãŸãƒ†ã‚£ãƒƒã‚«ãƒ¼:", "-" * 40, ""]
        
        # ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’10å€‹ãšã¤1è¡Œã«è¡¨ç¤º
        tickers = [stock.ticker for stock in results]
        for i in range(0, len(tickers), 10):
            line_tickers = tickers[i:i+10]
            output_lines.append(" | ".join(line_tickers))
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in volume_surge_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]



@server.tool()
def get_stock_fundamentals(
    ticker: str,
    data_fields: Optional[List[str]] = None
) -> List[TextContent]:
    """
    å€‹åˆ¥éŠ˜æŸ„ã®ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆå…¨128ã‚«ãƒ©ãƒ å¯¾å¿œï¼‰
    
    Args:
        ticker: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼
        data_fields: å–å¾—ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰
    """
    try:
        # Validate ticker
        if not validate_ticker(ticker):
            raise ValueError(f"Invalid ticker: {ticker}")
        
        # Validate data fields
        if data_fields:
            field_errors = validate_data_fields(data_fields)
            if field_errors:
                raise ValueError(f"Invalid data fields: {', '.join(field_errors)}")
        
        # Get fundamental data
        fundamental_data = finviz_client.get_stock_fundamentals(ticker, data_fields)
        
        if not fundamental_data:
            return [TextContent(type="text", text=f"No data found for ticker: {ticker}")]
        
        # Format output with categories
        output_lines = [
            f"ğŸ“Š Fundamental Data for {ticker}:",
            "=" * 60,
            ""
        ]
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
        def get_data(key, default=None):
            if isinstance(fundamental_data, dict):
                return fundamental_data.get(key, default)
            else:
                return getattr(fundamental_data, key, default)
        
        # é‡è¦ãªåŸºæœ¬æƒ…å ±ã‚’æœ€åˆã«è¡¨ç¤º
        basic_info = {
            'Company': get_data('company_name'),
            'Sector': get_data('sector'),
            'Industry': get_data('industry'),
            'Country': get_data('country'),
            'Market Cap': get_data('market_cap'),
            'Price': get_data('price'),
            'Volume': get_data('volume'),
            'Avg Volume': get_data('avg_volume')
        }
        
        output_lines.append("ğŸ“‹ Basic Information:")
        output_lines.append("-" * 30)
        for key, value in basic_info.items():
            if value is not None:
                if key == 'Price' and isinstance(value, (int, float)):
                    output_lines.append(f"{key:15}: ${value:.2f}")
                elif key in ['Volume', 'Avg Volume'] and isinstance(value, (int, float)):
                    output_lines.append(f"{key:15}: {value:,}")
                elif key == 'Market Cap' and isinstance(value, (int, float)):
                    if value >= 1e9:
                        output_lines.append(f"{key:15}: ${value/1e9:.2f}B")
                    elif value >= 1e6:
                        output_lines.append(f"{key:15}: ${value/1e6:.2f}M")
                    else:
                        output_lines.append(f"{key:15}: ${value:,.0f}")
                else:
                    output_lines.append(f"{key:15}: {value}")
        output_lines.append("")
        
        # ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ¨™
        valuation_metrics = {
            'P/E Ratio': get_data('pe_ratio'),
            'Forward P/E': get_data('forward_pe'),
            'PEG': get_data('peg'),
            'P/S Ratio': get_data('ps_ratio'),
            'P/B Ratio': get_data('pb_ratio'),
            'EPS': get_data('eps'),
            'Dividend Yield': get_data('dividend_yield')
        }
        
        if any(v is not None for v in valuation_metrics.values()):
            output_lines.append("ğŸ’° Valuation Metrics:")
            output_lines.append("-" * 30)
            for key, value in valuation_metrics.items():
                if value is not None:
                    if key == 'Dividend Yield' and isinstance(value, (int, float)):
                        output_lines.append(f"{key:15}: {value:.2f}%")
                    elif isinstance(value, (int, float)):
                        output_lines.append(f"{key:15}: {value:.2f}")
                    else:
                        output_lines.append(f"{key:15}: {value}")
            output_lines.append("")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
        performance_metrics = {
            '1 Week': get_data('performance_1w'),
            '1 Month': get_data('performance_1m'),
            '3 Months': get_data('performance_3m'),
            '6 Months': get_data('performance_6m'),
            'YTD': get_data('performance_ytd'),
            '1 Year': get_data('performance_1y')
        }
        
        if any(v is not None for v in performance_metrics.values()):
            output_lines.append("ğŸ“ˆ Performance:")
            output_lines.append("-" * 30)
            for key, value in performance_metrics.items():
                if value is not None and isinstance(value, (int, float)):
                    output_lines.append(f"{key:15}: {value:+.2f}%")
            output_lines.append("")
        
        # æ±ºç®—é–¢é€£ãƒ‡ãƒ¼ã‚¿
        earnings_data = {
            'Earnings Date': get_data('earnings_date'),
            'EPS Surprise': get_data('eps_surprise'),
            'Revenue Surprise': get_data('revenue_surprise'),
            'EPS Growth QoQ': get_data('eps_growth_qtr'),
            'Sales Growth QoQ': get_data('sales_growth_qtr')
        }
        
        if any(v is not None for v in earnings_data.values()):
            output_lines.append("ğŸ“Š Earnings Data:")
            output_lines.append("-" * 30)
            for key, value in earnings_data.items():
                if value is not None:
                    if key in ['EPS Surprise', 'Revenue Surprise', 'EPS Growth QoQ', 'Sales Growth QoQ'] and isinstance(value, (int, float)):
                        output_lines.append(f"{key:15}: {value:+.2f}%")
                    else:
                        output_lines.append(f"{key:15}: {value}")
            output_lines.append("")
        
        # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
        technical_data = {
            'RSI': get_data('rsi'),
            'Beta': get_data('beta'),
            'Volatility': get_data('volatility'),
            'Relative Volume': get_data('relative_volume'),
            '52W High': get_data('week_52_high'),
            '52W Low': get_data('week_52_low')
        }
        
        if any(v is not None for v in technical_data.values()):
            output_lines.append("ğŸ”§ Technical Indicators:")
            output_lines.append("-" * 30)
            for key, value in technical_data.items():
                if value is not None:
                    if key in ['52W High', '52W Low'] and isinstance(value, (int, float)):
                        output_lines.append(f"{key:15}: ${value:.2f}")
                    elif isinstance(value, (int, float)):
                        output_lines.append(f"{key:15}: {value:.2f}")
                    else:
                        output_lines.append(f"{key:15}: {value}")
            output_lines.append("")
        
        # å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è¦ç´„æƒ…å ±
        # fundamental_dataãŒè¾æ›¸ã‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚’åˆ¤åˆ¥
        if isinstance(fundamental_data, dict):
            fundamental_data_dict = fundamental_data
        else:
            fundamental_data_dict = fundamental_data.to_dict() if hasattr(fundamental_data, 'to_dict') else dict(fundamental_data)
            
        non_null_fields = sum(1 for v in fundamental_data_dict.values() if v is not None)
        total_fields = len(fundamental_data_dict)
        
        output_lines.extend([
            f"ğŸ“‹ Data Coverage: {non_null_fields}/{total_fields} fields ({non_null_fields/total_fields*100:.1f}%)",
            f"ğŸ” All Available Fields: {', '.join(sorted([k for k, v in fundamental_data_dict.items() if v is not None]))}"
        ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_stock_fundamentals: {str(e)}")
        raise e  # Re-raise validation errors
    except Exception as e:
        logger.error(f"Error in get_stock_fundamentals: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_multiple_stocks_fundamentals(
    tickers: List[str],
    data_fields: Optional[List[str]] = None
) -> List[TextContent]:
    """
    è¤‡æ•°éŠ˜æŸ„ã®ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å–å¾—ï¼ˆå…¨128ã‚«ãƒ©ãƒ å¯¾å¿œï¼‰
    
    Args:
        tickers: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆ
        data_fields: å–å¾—ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰
    """
    try:
        if not tickers:
            raise ValueError("No tickers provided")
        
        # Validate all tickers
        invalid_tickers = [ticker for ticker in tickers if not validate_ticker(ticker)]
        if invalid_tickers:
            raise ValueError(f"Invalid tickers: {', '.join(invalid_tickers)}")
        
        # Validate data fields
        if data_fields:
            field_errors = validate_data_fields(data_fields)
            if field_errors:
                raise ValueError(f"Invalid data fields: {', '.join(field_errors)}")
        
        results = finviz_client.get_multiple_stocks_fundamentals(tickers, data_fields)
        
        if not results:
            return [TextContent(type="text", text="No data found for any of the provided tickers.")]
        
        # Format output with enhanced table view
        output_lines = [
            f"ğŸ“Š Fundamental Data for {len(results)} stocks:",
            "=" * 80,
            ""
        ]
        
        # Create comparison table for key metrics
        key_metrics = [
            ('Ticker', 'ticker'),
            ('Company', 'company_name'),
            ('Sector', 'sector'),
            ('Price', 'price'),
            ('Market Cap', 'market_cap'),
            ('P/E', 'pe_ratio'),
            ('Volume', 'volume'),
            ('1W Perf', 'performance_1w'),
            ('EPS Surprise', 'eps_surprise')
        ]
        
        # Table header
        header = " | ".join([f"{name:12}" for name, _ in key_metrics])
        output_lines.append(header)
        output_lines.append("-" * len(header))
        
        # Table rows
        for result in results:
            row_values = []
            for name, field in key_metrics:
                value = getattr(result, field, None)
                if value is not None:
                    if field == 'price' and isinstance(value, (int, float)):
                        row_values.append(f"${value:.2f}".ljust(12))
                    elif field == 'market_cap' and isinstance(value, (int, float)):
                        if value >= 1e9:
                            row_values.append(f"${value/1e9:.1f}B".ljust(12))
                        elif value >= 1e6:
                            row_values.append(f"${value/1e6:.1f}M".ljust(12))
                        else:
                            row_values.append(f"${value:,.0f}".ljust(12))
                    elif field in ['pe_ratio', 'performance_1w', 'eps_surprise'] and isinstance(value, (int, float)):
                        row_values.append(f"{value:.2f}".ljust(12))
                    elif field == 'volume' and isinstance(value, (int, float)):
                        if value >= 1e6:
                            row_values.append(f"{value/1e6:.1f}M".ljust(12))
                        elif value >= 1e3:
                            row_values.append(f"{value/1e3:.1f}K".ljust(12))
                        else:
                            row_values.append(f"{value:,.0f}".ljust(12))
                    else:
                        str_value = str(value)
                        if len(str_value) > 12:
                            str_value = str_value[:9] + "..."
                        row_values.append(str_value.ljust(12))
                else:
                    row_values.append("N/A".ljust(12))
            
            row = " | ".join(row_values)
            output_lines.append(row)
        
        output_lines.append("")
        
        # Detailed breakdown for each stock
        output_lines.append("ğŸ“‹ Detailed Data:")
        output_lines.append("=" * 40)
        
        for i, result in enumerate(results, 1):
            ticker = getattr(result, 'ticker', 'Unknown')
            output_lines.append(f"\n{i}. {ticker} - {getattr(result, 'company_name', 'N/A')}")
            output_lines.append("-" * 50)
            
            # Categorized data
            categories = {
                "ğŸ“ˆ Performance": [
                    ('1W', 'performance_1w'), ('1M', 'performance_1m'), 
                    ('3M', 'performance_3m'), ('YTD', 'performance_ytd')
                ],
                "ğŸ’° Valuation": [
                    ('P/E', 'pe_ratio'), ('Forward P/E', 'forward_pe'),
                    ('PEG', 'peg'), ('P/S', 'ps_ratio'), ('P/B', 'pb_ratio')
                ],
                "ğŸ“Š Earnings": [
                    ('EPS', 'eps'), ('EPS Surprise', 'eps_surprise'),
                    ('Revenue Surprise', 'revenue_surprise'),
                    ('EPS Growth QoQ', 'eps_growth_qtr')
                ],
                "ğŸ”§ Technical": [
                    ('RSI', 'rsi'), ('Beta', 'beta'),
                    ('Volatility', 'volatility'), ('Relative Vol', 'relative_volume')
                ]
            }
            
            for category, fields in categories.items():
                values = [(name, getattr(result, field, None)) for name, field in fields if getattr(result, field, None) is not None]
                if values:
                    output_lines.append(f"  {category}: " + ", ".join([
                        f"{name}={val:.2f}{'%' if 'Performance' in category or name in ['EPS Surprise', 'Revenue Surprise'] else ''}"
                        if isinstance(val, (int, float)) else f"{name}={val}"
                        for name, val in values
                    ]))
            
            # Data coverage
            result_dict = result.to_dict() if hasattr(result, 'to_dict') else dict(result)
            non_null_fields = sum(1 for v in result_dict.values() if v is not None)
            total_fields = len(result_dict)
            output_lines.append(f"  ğŸ“‹ Data Coverage: {non_null_fields}/{total_fields} fields ({non_null_fields/total_fields*100:.1f}%)")
        
        # Summary
        output_lines.extend([
            "",
            "ğŸ“Š Summary:",
            f"Total stocks processed: {len(results)}",
            f"Average data coverage: {sum(sum(1 for v in (result.to_dict() if hasattr(result, 'to_dict') else dict(result)).values() if v is not None)/len(result.to_dict() if hasattr(result, 'to_dict') else dict(result)) for result in results)/len(results)*100:.1f}%"
        ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_multiple_stocks_fundamentals: {str(e)}")
        raise e  # Re-raise validation errors
    except Exception as e:
        logger.error(f"Error in get_multiple_stocks_fundamentals: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def trend_reversion_screener(
    market_cap: Optional[str] = "mid_large",
    eps_growth_qoq: Optional[float] = None,
    revenue_growth_qoq: Optional[float] = None,
    rsi_max: Optional[float] = None,
    sectors: Optional[List[str]] = None,
    exclude_sectors: Optional[List[str]] = None
) -> List[TextContent]:
    """
    ãƒˆãƒ¬ãƒ³ãƒ‰åè»¢å€™è£œéŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    
    Args:
        market_cap: æ™‚ä¾¡ç·é¡ãƒ•ã‚£ãƒ«ã‚¿ (mid_large, large, mega)
        eps_growth_qoq: EPSæˆé•·ç‡(QoQ) æœ€ä½å€¤
        revenue_growth_qoq: å£²ä¸Šæˆé•·ç‡(QoQ) æœ€ä½å€¤
        rsi_max: RSIä¸Šé™å€¤
        sectors: å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼
        exclude_sectors: é™¤å¤–ã‚»ã‚¯ã‚¿ãƒ¼
    """
    try:
        params = {
            'market_cap': market_cap,
            'eps_growth_qoq': eps_growth_qoq,
            'revenue_growth_qoq': revenue_growth_qoq,
            'rsi_max': rsi_max,
            'sectors': sectors or [],
            'exclude_sectors': exclude_sectors or []
        }
        
        results = finviz_screener.trend_reversion_screener(**params)
        
        if not results:
            return [TextContent(type="text", text="No trend reversal candidates found.")]
        
        output_lines = [
            f"Trend Reversal Screening Results ({len(results)} stocks found):",
            "=" * 60,
            ""
        ]
        
        for stock in results:
            output_lines.extend([
                f"Ticker: {stock.ticker}",
                f"Company: {stock.company_name}",
                f"Sector: {stock.sector}",
                f"Price: ${stock.price:.2f}" if stock.price else "Price: N/A",
                f"P/E Ratio: {stock.pe_ratio:.2f}" if stock.pe_ratio else "P/E Ratio: N/A",
                f"RSI: {stock.rsi:.2f}" if stock.rsi else "RSI: N/A",
                f"EPS Growth: {stock.eps_qoq_growth:.2f}%" if stock.eps_qoq_growth else "EPS Growth: N/A",
                f"Revenue Growth: {stock.sales_qoq_growth:.2f}%" if stock.sales_qoq_growth else "Revenue Growth: N/A",
                "-" * 40,
                ""
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in trend_reversion_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def uptrend_screener() -> List[TextContent]:
    """
    ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰éŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå›ºå®šæ¡ä»¶ï¼‰
    
    å›ºå®šãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ï¼š
    - æ™‚ä¾¡ç·é¡ï¼šãƒã‚¤ã‚¯ãƒ­ä»¥ä¸Šï¼ˆ$50M+ï¼‰
    - å¹³å‡å‡ºæ¥é«˜ï¼š100Kä»¥ä¸Š
    - æ ªä¾¡ï¼š10ä»¥ä¸Š
    - 52é€±é«˜å€¤ã‹ã‚‰30%ä»¥å†…
    - 4é€±ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šæ˜‡
    - 20æ—¥ç§»å‹•å¹³å‡ç·šä¸Š
    - 200æ—¥ç§»å‹•å¹³å‡ç·šä¸Š
    - 50æ—¥ç§»å‹•å¹³å‡ç·šãŒ200æ—¥ç§»å‹•å¹³å‡ç·šä¸Š
    - æ ªå¼ã®ã¿
    - EPSæˆé•·ç‡ï¼ˆå¹´æ¬¡ï¼‰é™é †ã‚½ãƒ¼ãƒˆ
    
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãªã— - å…¨ã¦ã®æ¡ä»¶ã¯å›ºå®šã•ã‚Œã¦ã„ã¾ã™
    """
    try:
        # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§å®Ÿè¡Œ
        results = finviz_screener.uptrend_screener()
        
        if not results:
            return [TextContent(type="text", text="å›ºå®šæ¡ä»¶ã§ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # å›ºå®šæ¡ä»¶ã®è¡¨ç¤º
        fixed_conditions = [
            "å›ºå®šãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶:",
            "- æ™‚ä¾¡ç·é¡: ãƒã‚¤ã‚¯ãƒ­ä»¥ä¸Šï¼ˆ$50M+ï¼‰",
            "- å¹³å‡å‡ºæ¥é«˜: 100Kä»¥ä¸Š",
            "- æ ªä¾¡: $10ä»¥ä¸Š",
            "- 52é€±é«˜å€¤ã‹ã‚‰30%ä»¥å†…",
            "- 4é€±ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: ä¸Šæ˜‡",
            "- 20æ—¥ç§»å‹•å¹³å‡ç·šä¸Š",
            "- 200æ—¥ç§»å‹•å¹³å‡ç·šä¸Š", 
            "- 50æ—¥ç§»å‹•å¹³å‡ç·šãŒ200æ—¥ç§»å‹•å¹³å‡ç·šä¸Š",
            "- æ ªå¼ã®ã¿",
            "- EPSæˆé•·ç‡ï¼ˆå¹´æ¬¡ï¼‰é™é †ã‚½ãƒ¼ãƒˆ"
        ]
        
        # ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ã¿ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«è¡¨ç¤º
        tickers = [stock.ticker for stock in results]
        
        output_lines = [
            f"ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœ ({len(results)}éŠ˜æŸ„ç™ºè¦‹):",
            "=" * 60,
            ""
        ] + fixed_conditions + [
            "",
            f"æ¤œå‡ºã•ã‚ŒãŸéŠ˜æŸ„ ({len(tickers)}ä»¶):",
            "-" * 40,
            ""
        ]
        
        # ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’1è¡Œã«10å€‹ãšã¤è¡¨ç¤º
        ticker_lines = []
        for i in range(0, len(tickers), 10):
            line_tickers = tickers[i:i+10]
            ticker_lines.append("  " + " | ".join(line_tickers))
        
        output_lines.extend(ticker_lines)
        output_lines.append("")
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in uptrend_screener: {str(e)}")
        return [TextContent(type="text", text=f"ã‚¨ãƒ©ãƒ¼: {str(e)}")]

@server.tool()
def dividend_growth_screener(
    market_cap: Optional[str] = "midover",
    min_dividend_yield: Optional[float] = 2.0,
    max_dividend_yield: Optional[float] = None,
    min_dividend_growth: Optional[float] = None,
    min_payout_ratio: Optional[float] = None,
    max_payout_ratio: Optional[float] = None,
    min_roe: Optional[float] = None,
    max_debt_equity: Optional[float] = None,
    max_pb_ratio: Optional[float] = 5.0,
    max_pe_ratio: Optional[float] = 30.0,
    eps_growth_5y_positive: Optional[bool] = True,
    eps_growth_qoq_positive: Optional[bool] = True,
    eps_growth_yoy_positive: Optional[bool] = True,
    sales_growth_5y_positive: Optional[bool] = True,
    sales_growth_qoq_positive: Optional[bool] = True,
    country: Optional[str] = "USA",
    stocks_only: Optional[bool] = True,
    sort_by: Optional[str] = "sma200",
    sort_order: Optional[str] = "asc"
) -> List[TextContent]:
    """
    é…å½“æˆé•·éŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    
    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¡ä»¶ï¼ˆå¤‰æ›´å¯èƒ½ï¼‰ï¼š
    - æ™‚ä¾¡ç·é¡ï¼šãƒŸãƒƒãƒ‰ä»¥ä¸Š ($2B+)
    - é…å½“åˆ©å›ã‚Šï¼š2%ä»¥ä¸Š
    - EPS 5å¹´æˆé•·ç‡ï¼šãƒ—ãƒ©ã‚¹
    - EPS QoQæˆé•·ç‡ï¼šãƒ—ãƒ©ã‚¹
    - EPS YoYæˆé•·ç‡ï¼šãƒ—ãƒ©ã‚¹
    - PBRï¼š5ä»¥ä¸‹
    - PERï¼š30ä»¥ä¸‹
    - å£²ä¸Š5å¹´æˆé•·ç‡ï¼šãƒ—ãƒ©ã‚¹
    - å£²ä¸ŠQoQæˆé•·ç‡ï¼šãƒ—ãƒ©ã‚¹
    - åœ°åŸŸï¼šã‚¢ãƒ¡ãƒªã‚«
    - æ ªå¼ã®ã¿
    - 200æ—¥ç§»å‹•å¹³å‡ã§ã‚½ãƒ¼ãƒˆ
    
    Args:
        market_cap: æ™‚ä¾¡ç·é¡ãƒ•ã‚£ãƒ«ã‚¿ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: midover)
        min_dividend_yield: æœ€ä½é…å½“åˆ©å›ã‚Š (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2.0)
        max_dividend_yield: æœ€é«˜é…å½“åˆ©å›ã‚Š
        min_dividend_growth: æœ€ä½é…å½“æˆé•·ç‡
        min_payout_ratio: æœ€ä½é…å½“æ€§å‘
        max_payout_ratio: æœ€é«˜é…å½“æ€§å‘
        min_roe: æœ€ä½ROE
        max_debt_equity: æœ€é«˜è² å‚µæ¯”ç‡
        max_pb_ratio: æœ€é«˜PBR (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5.0)
        max_pe_ratio: æœ€é«˜PER (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30.0)
        eps_growth_5y_positive: EPS 5å¹´æˆé•·ç‡ãƒ—ãƒ©ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: True)
        eps_growth_qoq_positive: EPS QoQæˆé•·ç‡ãƒ—ãƒ©ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: True)
        eps_growth_yoy_positive: EPS YoYæˆé•·ç‡ãƒ—ãƒ©ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: True)
        sales_growth_5y_positive: å£²ä¸Š5å¹´æˆé•·ç‡ãƒ—ãƒ©ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: True)
        sales_growth_qoq_positive: å£²ä¸ŠQoQæˆé•·ç‡ãƒ—ãƒ©ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: True)
        country: åœ°åŸŸ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: USA)
        stocks_only: æ ªå¼ã®ã¿ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: True)
        sort_by: ã‚½ãƒ¼ãƒˆåŸºæº– (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: sma200)
        sort_order: ã‚½ãƒ¼ãƒˆé †åº (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: asc)
    """
    try:
        params = {
            'market_cap': market_cap,
            'min_dividend_yield': min_dividend_yield,
            'max_dividend_yield': max_dividend_yield,
            'min_dividend_growth': min_dividend_growth,
            'min_payout_ratio': min_payout_ratio,
            'max_payout_ratio': max_payout_ratio,
            'min_roe': min_roe,
            'max_debt_equity': max_debt_equity,
            'max_pb_ratio': max_pb_ratio,
            'max_pe_ratio': max_pe_ratio,
            'eps_growth_5y_positive': eps_growth_5y_positive,
            'eps_growth_qoq_positive': eps_growth_qoq_positive,
            'eps_growth_yoy_positive': eps_growth_yoy_positive,
            'sales_growth_5y_positive': sales_growth_5y_positive,
            'sales_growth_qoq_positive': sales_growth_qoq_positive,
            'country': country,
            'stocks_only': stocks_only,
            'sort_by': sort_by,
            'sort_order': sort_order
        }
        
        results = finviz_screener.dividend_growth_screener(**params)
        
        if not results:
            return [TextContent(type="text", text="No dividend growth stocks found.")]
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¡ä»¶ã®è¡¨ç¤º
        default_conditions = [
            "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¡ä»¶:",
            "- æ™‚ä¾¡ç·é¡: ãƒŸãƒƒãƒ‰ä»¥ä¸Š ($2B+)",
            "- é…å½“åˆ©å›ã‚Š: 2%ä»¥ä¸Š",
            "- EPS 5å¹´æˆé•·ç‡: ãƒ—ãƒ©ã‚¹",
            "- EPS QoQæˆé•·ç‡: ãƒ—ãƒ©ã‚¹",
            "- EPS YoYæˆé•·ç‡: ãƒ—ãƒ©ã‚¹",
            "- PBR: 5ä»¥ä¸‹",
            "- PER: 30ä»¥ä¸‹",
            "- å£²ä¸Š5å¹´æˆé•·ç‡: ãƒ—ãƒ©ã‚¹",
            "- å£²ä¸ŠQoQæˆé•·ç‡: ãƒ—ãƒ©ã‚¹",
            "- åœ°åŸŸ: ã‚¢ãƒ¡ãƒªã‚«",
            "- æ ªå¼ã®ã¿",
            "- 200æ—¥ç§»å‹•å¹³å‡ã§ã‚½ãƒ¼ãƒˆ"
        ]
        
        output_lines = [
            f"Dividend Growth Screening Results ({len(results)} stocks found):",
            "=" * 60,
            ""
        ]
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¡ä»¶ã‚’è¡¨ç¤º
        output_lines.extend(default_conditions)
        output_lines.extend(["", "=" * 60, ""])
        
        for stock in results:
            output_lines.extend([
                f"Ticker: {stock.ticker}",
                f"Company: {stock.company_name}",
                f"Sector: {stock.sector}",
                f"Price: ${stock.price:.2f}" if stock.price else "Price: N/A",
                f"Dividend Yield: {stock.dividend_yield:.2f}%" if stock.dividend_yield else "Dividend Yield: N/A",
                f"P/E Ratio: {stock.pe_ratio:.2f}" if stock.pe_ratio else "P/E Ratio: N/A",
                f"Market Cap: {stock.market_cap}" if stock.market_cap else "Market Cap: N/A",
                "-" * 40,
                ""
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in dividend_growth_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def etf_screener(
    strategy_type: Optional[str] = "long",
    asset_class: Optional[str] = "equity",
    min_aum: Optional[float] = None,
    max_expense_ratio: Optional[float] = None
) -> List[TextContent]:
    """
    ETFæˆ¦ç•¥ç”¨ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    
    Args:
        strategy_type: æˆ¦ç•¥ã‚¿ã‚¤ãƒ— (long, short)
        asset_class: è³‡ç”£ã‚¯ãƒ©ã‚¹ (equity, bond, commodity, currency)
        min_aum: æœ€ä½é‹ç”¨è³‡ç”£é¡
        max_expense_ratio: æœ€é«˜çµŒè²»ç‡
    """
    try:
        params = {
            'strategy_type': strategy_type,
            'asset_class': asset_class,
            'min_aum': min_aum,
            'max_expense_ratio': max_expense_ratio
        }
        
        results = finviz_screener.etf_screener(**params)
        
        if not results:
            return [TextContent(type="text", text="No ETFs found matching criteria.")]
        
        output_lines = [
            f"ETF Screening Results ({len(results)} ETFs found):",
            "=" * 60,
            ""
        ]
        
        for stock in results:
            output_lines.extend([
                f"Ticker: {stock.ticker}",
                f"Name: {stock.company_name}",
                f"Price: ${stock.price:.2f}" if stock.price else "Price: N/A",
                f"Volume: {stock.volume:,}" if stock.volume else "Volume: N/A",
                f"Change: {stock.price_change:.2f}%" if stock.price_change else "Change: N/A",
                "-" * 40,
                ""
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in etf_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def earnings_premarket_screener() -> List[TextContent]:
    """
    å¯„ã‚Šä»˜ãå‰æ±ºç®—ç™ºè¡¨ã§ä¸Šæ˜‡ã—ã¦ã„ã‚‹éŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå›ºå®šæ¡ä»¶ï¼‰
    
    å›ºå®šãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ï¼ˆå¤‰æ›´ä¸å¯ï¼‰ï¼š
    f=cap_smallover,earningsdate_todaybefore,sh_avgvol_o100,sh_price_o10,ta_change_u2&ft=4&o=-change
    
    - æ™‚ä¾¡ç·é¡ï¼šã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Šï¼ˆ$300M+ï¼‰
    - æ±ºç®—ç™ºè¡¨ï¼šä»Šæ—¥ã®å¯„ã‚Šä»˜ãå‰
    - å¹³å‡å‡ºæ¥é«˜ï¼š100Kä»¥ä¸Š
    - æ ªä¾¡ï¼š$10ä»¥ä¸Š
    - ä¾¡æ ¼å¤‰å‹•ï¼š2%ä»¥ä¸Šä¸Šæ˜‡
    - æ ªå¼ã®ã¿
    - ä¾¡æ ¼å¤‰å‹•é™é †ã‚½ãƒ¼ãƒˆ
    
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãªã— - å…¨ã¦ã®æ¡ä»¶ã¯å›ºå®šã•ã‚Œã¦ã„ã¾ã™
    """
    try:
        # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§å®Ÿè¡Œ
        results = finviz_screener.earnings_premarket_screener()
        
        if not results:
            return [TextContent(type="text", text="å›ºå®šæ¡ä»¶ã§å¯„ã‚Šä»˜ãå‰æ±ºç®—éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # å›ºå®šæ¡ä»¶ã®è¡¨ç¤º
        fixed_conditions = [
            "å›ºå®šãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶:",
            "- æ™‚ä¾¡ç·é¡: ã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Šï¼ˆ$300M+ï¼‰",
            "- æ±ºç®—ç™ºè¡¨: ä»Šæ—¥ã®å¯„ã‚Šä»˜ãå‰",
            "- å¹³å‡å‡ºæ¥é«˜: 100Kä»¥ä¸Š",
            "- æ ªä¾¡: $10ä»¥ä¸Š",
            "- ä¾¡æ ¼å¤‰å‹•: 2%ä»¥ä¸Šä¸Šæ˜‡",
            "- æ ªå¼ã®ã¿",
            "- ä¾¡æ ¼å¤‰å‹•é™é †ã‚½ãƒ¼ãƒˆ"
        ]
        
        # è©³ç´°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡ºåŠ›ã‚’ä½¿ç”¨ï¼ˆå›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ï¼‰
        params = {'earnings_timing': 'today_before', 'market_cap': 'smallover'}
        formatted_output = _format_earnings_premarket_list(results, params)
        
        return [TextContent(type="text", text="\n".join(fixed_conditions + [""] + formatted_output))]
        
    except Exception as e:
        logger.error(f"Error in earnings_premarket_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def earnings_afterhours_screener() -> List[TextContent]:
    """
    å¼•ã‘å¾Œæ±ºç®—ç™ºè¡¨ã§æ™‚é–“å¤–å–å¼•ä¸Šæ˜‡éŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå›ºå®šæ¡ä»¶ï¼‰
    
    å›ºå®šãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ï¼ˆå¤‰æ›´ä¸å¯ï¼‰ï¼š
    f=ah_change_u2,cap_smallover,earningsdate_todayafter,sh_avgvol_o100,sh_price_o10&ft=4&o=-afterchange&ar=60
    
    - æ™‚é–“å¤–å¤‰å‹•ï¼š2%ä»¥ä¸Šä¸Šæ˜‡
    - æ™‚ä¾¡ç·é¡ï¼šã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Šï¼ˆ$300M+ï¼‰
    - æ±ºç®—ç™ºè¡¨ï¼šä»Šæ—¥ã®å¼•ã‘å¾Œ
    - å¹³å‡å‡ºæ¥é«˜ï¼š100Kä»¥ä¸Š
    - æ ªä¾¡ï¼š$10ä»¥ä¸Š
    - æ ªå¼ã®ã¿
    - æ™‚é–“å¤–å¤‰å‹•é™é †ã‚½ãƒ¼ãƒˆ
    - æœ€å¤§çµæœï¼š60ä»¶
    
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãªã— - å…¨ã¦ã®æ¡ä»¶ã¯å›ºå®šã•ã‚Œã¦ã„ã¾ã™
    """
    try:
        # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§å®Ÿè¡Œ
        results = finviz_screener.earnings_afterhours_screener()
        
        if not results:
            return [TextContent(type="text", text="å›ºå®šæ¡ä»¶ã§å¼•ã‘å¾Œæ±ºç®—éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # å›ºå®šæ¡ä»¶ã®è¡¨ç¤º
        fixed_conditions = [
            "å›ºå®šãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶:",
            "- æ™‚é–“å¤–å¤‰å‹•: 2%ä»¥ä¸Šä¸Šæ˜‡",
            "- æ™‚ä¾¡ç·é¡: ã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Šï¼ˆ$300M+ï¼‰",
            "- æ±ºç®—ç™ºè¡¨: ä»Šæ—¥ã®å¼•ã‘å¾Œ",
            "- å¹³å‡å‡ºæ¥é«˜: 100Kä»¥ä¸Š",
            "- æ ªä¾¡: $10ä»¥ä¸Š",
            "- æ ªå¼ã®ã¿",
            "- æ™‚é–“å¤–å¤‰å‹•é™é †ã‚½ãƒ¼ãƒˆ",
            "- æœ€å¤§çµæœ: 60ä»¶"
        ]
        
        # è©³ç´°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡ºåŠ›ã‚’ä½¿ç”¨ï¼ˆå›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ï¼‰
        params = {'earnings_timing': 'today_after', 'market_cap': 'smallover'}
        formatted_output = _format_earnings_afterhours_list(results, params)
        
        return [TextContent(type="text", text="\n".join(fixed_conditions + [""] + formatted_output))]
        
    except Exception as e:
        logger.error(f"Error in earnings_afterhours_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def earnings_trading_screener() -> List[TextContent]:
    """
    æ±ºç®—ãƒˆãƒ¬ãƒ¼ãƒ‰å¯¾è±¡éŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå›ºå®šæ¡ä»¶ï¼‰
    
    å›ºå®šãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ï¼ˆå¤‰æ›´ä¸å¯ï¼‰ï¼š
    f=cap_smallover,earningsdate_yesterdayafter|todaybefore,fa_epsrev_ep,sh_avgvol_o200,sh_price_o10,ta_change_u,ta_perf_0to-4w,ta_volatility_1tox&ft=4&o=-epssurprise&ar=60
    
    - æ™‚ä¾¡ç·é¡ï¼šã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Š ($300M+)
    - æ±ºç®—ç™ºè¡¨ï¼šæ˜¨æ—¥ã®å¼•ã‘å¾Œã¾ãŸã¯ä»Šæ—¥ã®å¯„ã‚Šä»˜ãå‰
    - EPSäºˆæƒ³ï¼šä¸Šæ–¹ä¿®æ­£
    - å¹³å‡å‡ºæ¥é«˜ï¼š200,000ä»¥ä¸Š
    - æ ªä¾¡ï¼š$10ä»¥ä¸Š
    - ä¾¡æ ¼å¤‰å‹•ï¼šä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰
    - 4é€±ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼š0%ã‹ã‚‰ä¸‹è½ï¼ˆä¸‹è½å¾Œå›å¾©å€™è£œï¼‰
    - ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼š1å€ä»¥ä¸Š
    - æ ªå¼ã®ã¿
    - EPSã‚µãƒ—ãƒ©ã‚¤ã‚ºé™é †ã‚½ãƒ¼ãƒˆ
    - æœ€å¤§çµæœä»¶æ•°ï¼š60ä»¶
    
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãªã— - å…¨ã¦ã®æ¡ä»¶ã¯å›ºå®šã•ã‚Œã¦ã„ã¾ã™
    """
    try:
        # å›ºå®šæ¡ä»¶ã§å®Ÿè¡Œï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãªã—ï¼‰
        results = finviz_screener.earnings_trading_screener()
        
        if not results:
            return [TextContent(type="text", text="æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ã§æ±ºç®—ãƒˆãƒ¬ãƒ¼ãƒ‰å¯¾è±¡éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # å›ºå®šæ¡ä»¶ã®è¡¨ç¤º
        fixed_conditions = [
            "å›ºå®šãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶:",
            "- æ™‚ä¾¡ç·é¡: ã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Š ($300M+)",
            "- æ±ºç®—ç™ºè¡¨: æ˜¨æ—¥ã®å¼•ã‘å¾Œã¾ãŸã¯ä»Šæ—¥ã®å¯„ã‚Šä»˜ãå‰",
            "- EPSäºˆæƒ³: ä¸Šæ–¹ä¿®æ­£",
            "- å¹³å‡å‡ºæ¥é«˜: 200,000ä»¥ä¸Š",
            "- æ ªä¾¡: $10ä»¥ä¸Š",
            "- ä¾¡æ ¼å¤‰å‹•: ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰",
            "- 4é€±ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: 0%ã‹ã‚‰ä¸‹è½ï¼ˆä¸‹è½å¾Œå›å¾©å€™è£œï¼‰",
            "- ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: 1å€ä»¥ä¸Š",
            "- æ ªå¼ã®ã¿",
            "- EPSã‚µãƒ—ãƒ©ã‚¤ã‚ºé™é †ã‚½ãƒ¼ãƒˆ",
            "- æœ€å¤§çµæœä»¶æ•°: 60ä»¶"
        ]
        
        # ç°¡æ½”ãªå‡ºåŠ›å½¢å¼ï¼ˆãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ã¿ï¼‰
        output_lines = [
            f"æ±ºç®—ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœ ({len(results)}éŠ˜æŸ„ç™ºè¦‹):",
            "=" * 60,
            ""
        ] + fixed_conditions + ["", "æ¤œå‡ºã•ã‚ŒãŸãƒ†ã‚£ãƒƒã‚«ãƒ¼:", "-" * 40, ""]
        
        # ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’10å€‹ãšã¤1è¡Œã«è¡¨ç¤º
        tickers = [stock.ticker for stock in results]
        for i in range(0, len(tickers), 10):
            line_tickers = tickers[i:i+10]
            output_lines.append(" | ".join(line_tickers))
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in earnings_trading_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]



@server.tool()
def get_stock_news(
    tickers: Union[str, List[str]],
    days_back: int = 7,
    news_type: Optional[str] = "all"
) -> List[TextContent]:
    """
    éŠ˜æŸ„é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å–å¾—
    
    Args:
        tickers: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆå˜ä¸€æ–‡å­—åˆ—ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã€ã¾ãŸã¯ãƒªã‚¹ãƒˆï¼‰
        days_back: éå»ä½•æ—¥åˆ†ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹
        news_type: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ— (all, earnings, analyst, insider, general)
    """
    try:
        from .utils.validators import validate_tickers, parse_tickers
        
        # Validate tickers
        if not validate_tickers(tickers):
            raise ValueError(f"Invalid tickers: {tickers}")
        
        # Validate days_back
        if days_back <= 0:
            raise ValueError(f"Invalid days_back: {days_back}")
        
        # Parse tickers for display
        ticker_list = parse_tickers(tickers)
        ticker_display = ', '.join(ticker_list)
        
        # Get news data
        news_list = finviz_news.get_stock_news(tickers, days_back or 7, news_type or "all")
        
        if not news_list:
            return [TextContent(type="text", text=f"No news found for {ticker_display} in the last {days_back} days.")]
        
        # Format output
        if len(ticker_list) == 1:
            header = f"News for {ticker_display} (last {days_back} days):"
        else:
            header = f"News for {ticker_display} (last {days_back} days):"
        
        output_lines = [
            header,
            "=" * 50,
            ""
        ]
        
        for news in news_list:
            output_lines.extend([
                f"ğŸ“° {news.title}",
                f"ğŸ¢ Source: {news.source}",
                f"ğŸ“… Date: {news.date.strftime('%Y-%m-%d %H:%M')}",
                f"ğŸ·ï¸ Category: {news.category}",
                f"ğŸ”— URL: {news.url}",
                "-" * 40,
                ""
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_stock_news: {str(e)}")
        raise e  # Re-raise validation errors
    except Exception as e:
        logger.error(f"Error in get_stock_news: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_market_news(
    days_back: int = 3,
    max_items: int = 20
) -> List[TextContent]:
    """
    å¸‚å ´å…¨ä½“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—
    
    Args:
        days_back: éå»ä½•æ—¥åˆ†ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹
        max_items: æœ€å¤§å–å¾—ä»¶æ•°
    """
    try:
        # Get market news
        news_list = finviz_news.get_market_news(days_back or 3, max_items or 20)
        
        if not news_list:
            return [TextContent(type="text", text=f"No market news found in the last {days_back} days.")]
        
        # Format output
        output_lines = [
            f"Market News (last {days_back} days):",
            "=" * 50,
            ""
        ]
        
        for news in news_list:
            output_lines.extend([
                f"ğŸ“° {news.title}",
                f"ğŸ¢ Source: {news.source}",
                f"ğŸ“… Date: {news.date.strftime('%Y-%m-%d %H:%M')}",
                f"ğŸ·ï¸ Category: {news.category}",
                f"ğŸ”— URL: {news.url}",
                "-" * 30,
                ""
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in get_market_news: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_sector_news(
    sector: str,
    days_back: int = 5,
    max_items: int = 15
) -> List[TextContent]:
    """
    ç‰¹å®šã‚»ã‚¯ã‚¿ãƒ¼ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—
    
    Args:
        sector: ã‚»ã‚¯ã‚¿ãƒ¼å
        days_back: éå»ä½•æ—¥åˆ†ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹
        max_items: æœ€å¤§å–å¾—ä»¶æ•°
    """
    try:
        # Get sector news
        news_list = finviz_news.get_sector_news(sector, days_back or 5, max_items or 15)
        
        if not news_list:
            return [TextContent(type="text", text=f"No news found for {sector} sector in the last {days_back} days.")]
        
        # Format output
        output_lines = [
            f"{sector} Sector News (last {days_back} days):",
            "=" * 50,
            ""
        ]
        
        for news in news_list:
            output_lines.extend([
                f"ğŸ“° {news.title}",
                f"ğŸ¢ Source: {news.source}",
                f"ğŸ“… Date: {news.date.strftime('%Y-%m-%d %H:%M')}",
                f"ğŸ·ï¸ Category: {news.category}",
                f"ğŸ”— URL: {news.url}",
                "-" * 30,
                ""
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in get_sector_news: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_sector_performance(
    sectors: Optional[List[str]] = None
) -> List[TextContent]:
    """
    ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    
    Args:
        sectors: å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼
    """
    try:
        # Get sector performance data
        sector_data = finviz_sector.get_sector_performance(sectors)
        
        if not sector_data:
            return [TextContent(type="text", text="No sector performance data found.")]
        
        # Format output
        output_lines = [
            "Sector Performance Analysis:",
            "=" * 60,
            ""
        ]
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’å®Ÿéš›ã®ã‚«ãƒ©ãƒ ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦èª¿æ•´
        output_lines.extend([
            f"{'Sector':<30} {'Market Cap':<15} {'P/E':<8} {'Div Yield':<10} {'Change':<8} {'Stocks':<6}",
            "-" * 75
        ])
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for sector in sector_data:
            output_lines.append(
                f"{sector.get('name', 'N/A'):<30} "
                f"{sector.get('market_cap', 'N/A'):<15} "
                f"{sector.get('pe_ratio', 'N/A'):<8} "
                f"{sector.get('dividend_yield', 'N/A'):<10} "
                f"{sector.get('change', 'N/A'):<8} "
                f"{sector.get('stocks', 'N/A'):<6}"
            )
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in get_sector_performance: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_industry_performance(
    industries: Optional[List[str]] = None
) -> List[TextContent]:
    """
    æ¥­ç•Œåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    
    Args:
        industries: å¯¾è±¡æ¥­ç•Œ
    """
    try:
        # Get industry performance data
        industry_data = finviz_sector.get_industry_performance(industries)
        
        if not industry_data:
            return [TextContent(type="text", text="No industry performance data found.")]
        
        # Format output
        output_lines = [
            "Industry Performance Analysis:",
            "=" * 60,
            ""
        ]
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        output_lines.extend([
            f"{'Industry':<40} {'Market Cap':<15} {'P/E':<8} {'Change':<8} {'Stocks':<6}",
            "-" * 80
        ])
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for industry in industry_data:
            output_lines.append(
                f"{industry.get('industry', 'N/A'):<40} "
                f"{industry.get('market_cap', 'N/A'):<15} "
                f"{industry.get('pe_ratio', 'N/A'):<8} "
                f"{industry.get('change', 'N/A'):<8} "
                f"{industry.get('stocks', 'N/A'):<6}"
            )
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in get_industry_performance: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_country_performance(
    countries: Optional[List[str]] = None
) -> List[TextContent]:
    """
    å›½åˆ¥å¸‚å ´ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    
    Args:
        countries: å¯¾è±¡å›½
    """
    try:
        # Get country performance data
        country_data = finviz_sector.get_country_performance(countries)
        
        if not country_data:
            return [TextContent(type="text", text="No country performance data found.")]
        
        # Format output
        output_lines = [
            "Country Performance Analysis:",
            "=" * 60,
            ""
        ]
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        output_lines.extend([
            f"{'Country':<30} {'Market Cap':<15} {'P/E':<8} {'Change':<8} {'Stocks':<6}",
            "-" * 70
        ])
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for country in country_data:
            output_lines.append(
                f"{country.get('country', 'N/A'):<30} "
                f"{country.get('market_cap', 'N/A'):<15} "
                f"{country.get('pe_ratio', 'N/A'):<8} "
                f"{country.get('change', 'N/A'):<8} "
                f"{country.get('stocks', 'N/A'):<6}"
            )
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in get_country_performance: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_sector_specific_industry_performance(
    sector: str
) -> List[TextContent]:
    """
    ç‰¹å®šã‚»ã‚¯ã‚¿ãƒ¼å†…ã®æ¥­ç•Œåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    
    åˆ©ç”¨å¯èƒ½ãªã‚»ã‚¯ã‚¿ãƒ¼:
    - basicmaterials (Basic Materials)
    - communicationservices (Communication Services) 
    - consumercyclical (Consumer Cyclical)
    - consumerdefensive (Consumer Defensive)
    - energy (Energy)
    - financial (Financial)
    - healthcare (Healthcare)
    - industrials (Industrials)
    - realestate (Real Estate)
    - technology (Technology)
    - utilities (Utilities)
    
    Args:
        sector: ã‚»ã‚¯ã‚¿ãƒ¼å (ä¸Šè¨˜ã®ã‚»ã‚¯ã‚¿ãƒ¼åã‹ã‚‰é¸æŠ)
        timeframe: åˆ†ææœŸé–“ (1d, 1w, 1m, 3m, 6m, 1y)
    """
    try:
        # Get sector-specific industry performance data
        industry_data = finviz_sector.get_sector_specific_industry_performance(sector)
        
        if not industry_data:
            return [TextContent(type="text", text=f"No industry performance data found for {sector} sector.")]
        
        # Format output
        sector_display = sector.replace('_', ' ').title()
        output_lines = [
            f"{sector_display} Sector - Industry Performance Analysis:",
            "=" * 70,
            ""
        ]
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        output_lines.extend([
            f"{'Industry':<45} {'Market Cap':<15} {'P/E':<8} {'Change':<8} {'Stocks':<6}",
            "-" * 85
        ])
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for industry in industry_data:
            output_lines.append(
                f"{industry.get('industry', 'N/A'):<45} "
                f"{industry.get('market_cap', 'N/A'):<15} "
                f"{industry.get('pe_ratio', 'N/A'):<8} "
                f"{industry.get('change', 'N/A'):<8} "
                f"{industry.get('stocks', 'N/A'):<6}"
            )
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in get_sector_specific_industry_performance: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_capitalization_performance() -> List[TextContent]:
    """
    æ™‚ä¾¡ç·é¡åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    """
    try:
        # Get capitalization performance data
        cap_data = finviz_sector.get_capitalization_performance()
        
        if not cap_data:
            return [TextContent(type="text", text="No capitalization performance data found.")]
        
        # Format output
        output_lines = [
            "Capitalization Performance Analysis:",
            "=" * 70,
            ""
        ]
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        output_lines.extend([
            f"{'Capitalization':<30} {'Market Cap':<15} {'P/E':<8} {'Change':<8} {'Stocks':<6}",
            "-" * 70
        ])
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for cap in cap_data:
            output_lines.append(
                f"{cap.get('capitalization', 'N/A'):<30} "
                f"{cap.get('market_cap', 'N/A'):<15} "
                f"{cap.get('pe_ratio', 'N/A'):<8} "
                f"{cap.get('change', 'N/A'):<8} "
                f"{cap.get('stocks', 'N/A'):<6}"
            )
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in get_capitalization_performance: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_market_overview() -> List[TextContent]:
    """
    å¸‚å ´å…¨ä½“ã®æ¦‚è¦ã‚’å–å¾—ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ï¼‰
    """
    try:
        import pandas as pd
        
        logger.info("Retrieving real market overview data...")
        
        # ä¸»è¦ETFã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæä¾›ã—ãŸãƒ‡ãƒ¼ã‚¿ã¨ä¸€è‡´ï¼‰
        major_etfs = ['SPY', 'QQQ', 'DIA', 'IWM', 'TLT', 'GLD']
        
        # 1. ä¸»è¦ETFã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬å–å¾—ï¼ˆFinvizã®å®Ÿãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åä½¿ç”¨ï¼‰
        logger.info("Fetching major ETF data using Finviz bulk API...")
        try:
            # å®Ÿéš›ã®Finvizãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å¯¾å¿œ
            etf_data_bulk = finviz_client.get_multiple_stocks_fundamentals(
                major_etfs,
                data_fields=['ticker', 'company', 'price', 'change', 'volume', 'market_cap']
            )
            logger.info(f"Successfully retrieved data for {len(etf_data_bulk)} ETFs")
        except Exception as e:
            logger.warning(f"Bulk API failed: {e}, trying individual requests...")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå€‹åˆ¥å–å¾—
            etf_data_bulk = []
            for ticker in major_etfs:
                try:
                    data = finviz_client.get_stock_fundamentals(
                        ticker, 
                        data_fields=['ticker', 'company', 'price', 'change', 'volume', 'market_cap']
                    )
                    etf_data_bulk.append(data)
                except Exception as etf_error:
                    logger.warning(f"Failed to get data for {ticker}: {etf_error}")
                    etf_data_bulk.append({'ticker': ticker, 'error': str(etf_error)})
        
        # 2. å¸‚å ´çµ±è¨ˆã‚’ä¸¦åˆ—å–å¾—
        logger.info("Calculating market statistics...")
        
        # å‡ºæ¥é«˜æ€¥å¢—éŠ˜æŸ„æ•°ã‚’å–å¾—
        try:
            volume_surge_results = finviz_screener.volume_surge_screener()
            volume_surge_count = len(volume_surge_results) if volume_surge_results else 0
            # çµ±è¨ˆè¨ˆç®—
            if volume_surge_results:
                avg_rel_vol = sum([getattr(stock, 'relative_volume', 0) for stock in volume_surge_results if hasattr(stock, 'relative_volume') and stock.relative_volume]) / len(volume_surge_results)
                avg_change = sum([getattr(stock, 'price_change', 0) for stock in volume_surge_results if hasattr(stock, 'price_change') and stock.price_change]) / len(volume_surge_results)
            else:
                avg_rel_vol = 0
                avg_change = 0
        except Exception as e:
            logger.warning(f"Volume surge calculation failed: {e}")
            volume_surge_count = 0
            avg_rel_vol = 0
            avg_change = 0
        
        # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰éŠ˜æŸ„æ•°ã‚’å–å¾—
        try:
            uptrend_results = finviz_screener.uptrend_screener()
            uptrend_count = len(uptrend_results) if uptrend_results else 0
            # ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æ
            if uptrend_results:
                sectors_count = {}
                for stock in uptrend_results:
                    sector = getattr(stock, 'sector', None)
                    if sector:
                        sectors_count[sector] = sectors_count.get(sector, 0) + 1
                top_sectors = dict(sorted(sectors_count.items(), key=lambda x: x[1], reverse=True)[:3])
            else:
                top_sectors = {}
        except Exception as e:
            logger.warning(f"Uptrend calculation failed: {e}")
            uptrend_count = 0
            top_sectors = {}
        
        # æ±ºç®—é–¢é€£çµ±è¨ˆ
        try:
            earnings_results = finviz_screener.earnings_screener(earnings_date="this_week")
            earnings_count = len(earnings_results) if earnings_results else 0
        except Exception as e:
            logger.warning(f"Earnings calculation failed: {e}")
            earnings_count = 0
        
        # ETFåç§°ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå®Ÿéš›ã®Finvizã¨ä¸€è‡´ï¼‰
        etf_names = {
            'SPY': 'SPDR S&P 500 ETF Trust',
            'QQQ': 'Invesco QQQ Trust Series 1',  
            'DIA': 'SPDR Dow Jones Industrial Average ETF',
            'IWM': 'iShares Russell 2000 ETF',
            'TLT': 'iShares 20+ Year Treasury Bond ETF',
            'GLD': 'SPDR Gold Shares ETF'
        }
        
        # å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        output_lines = [
            "ğŸ›ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¸‚å ´æ¦‚è¦",
            "=" * 70,
            f"ğŸ“… ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚åˆ»: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: Finviz.com (Live Data)",
            "",
            "ğŸ“ˆ ä¸»è¦ETFä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿:",
            "-" * 50
        ]
        
        # ETFãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸ã«å¤‰æ›ï¼ˆãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’ã‚­ãƒ¼ã¨ã—ã¦ï¼‰
        etf_data_dict = {}
        
        # ä¸€æ‹¬å–å¾—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒ™ãƒ¼ã‚¹ã®è¾æ›¸ã«å¤‰æ›
        if isinstance(etf_data_bulk, list):
            for data_item in etf_data_bulk:
                if isinstance(data_item, dict):
                    ticker_key = data_item.get('ticker')
                    if ticker_key:
                        etf_data_dict[ticker_key] = data_item
                else:
                    # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ã®å ´åˆ
                    if hasattr(data_item, 'ticker'):
                        ticker_key = getattr(data_item, 'ticker')
                        if ticker_key:
                            etf_data_dict[ticker_key] = {
                                'ticker': getattr(data_item, 'ticker', ''),
                                'company': getattr(data_item, 'company', ''),
                                'price': getattr(data_item, 'price', None),
                                'change': getattr(data_item, 'change', None),
                                'volume': getattr(data_item, 'volume', None),
                                'market_cap': getattr(data_item, 'market_cap', None)
                            }
        
        logger.info(f"Converted {len(etf_data_dict)} ETF records to dictionary")
        
        # ETFãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºï¼ˆãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒ™ãƒ¼ã‚¹ã§æ¤œç´¢ï¼‰
        for ticker in major_etfs:
            try:
                # è¾æ›¸ã‹ã‚‰ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã«å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                etf_data = etf_data_dict.get(ticker)
                
                if etf_data and not etf_data.get('error'):
                    name = etf_names.get(ticker, ticker)
                    
                    # ãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ãªå–å¾—
                    def get_safe_data(key, default='N/A'):
                        value = etf_data.get(key, default)
                        return value if value is not None else default
                    
                    price = get_safe_data('price')
                    change = get_safe_data('change')
                    volume = get_safe_data('volume')
                    market_cap = get_safe_data('market_cap')
                    
                    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†
                    if isinstance(price, (int, float)):
                        price_str = f"${price:.2f}"
                    else:
                        price_str = str(price)
                    
                    # å¤‰å‹•ç‡ã®å‡¦ç†ï¼ˆFinvizã‹ã‚‰ãã®ã¾ã¾ä½¿ç”¨ï¼‰
                    if isinstance(change, str) and '%' in change:
                        change_str = change  # æ—¢ã«%ä»˜ãã®å ´åˆ
                    elif isinstance(change, (int, float)):
                        change_str = f"{change:+.2f}%"
                    else:
                        change_str = str(change)
                    
                    # å‡ºæ¥é«˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                    if isinstance(volume, (int, float)):
                        volume_str = f"{int(volume):,}"
                    else:
                        volume_str = str(volume)
                    
                    # æ™‚ä¾¡ç·é¡ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ  
                    market_cap_str = str(market_cap) if market_cap != 'N/A' else 'N/A'
                    
                    # å¤‰å‹•æ–¹å‘ã®çµµæ–‡å­—
                    trend_emoji = "ğŸ“ˆ" if change_str.startswith('+') else "ğŸ“‰" if change_str.startswith('-') else "ğŸ“Š"
                    
                    output_lines.extend([
                        f"ğŸ”¹ {ticker} ({name})",
                        f"   ğŸ’° ä¾¡æ ¼: {price_str}  {trend_emoji} å¤‰å‹•: {change_str}",
                        f"   ğŸ“¦ å‡ºæ¥é«˜: {volume_str}  ğŸ’¼ æ™‚ä¾¡ç·é¡: {market_cap_str}",
                        ""
                    ])
                else:
                    # ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆã€å€‹åˆ¥å–å¾—ã‚’è©¦è¡Œ
                    logger.warning(f"No data found for {ticker} in bulk result, trying individual fetch...")
                    try:
                        individual_data = finviz_client.get_stock_fundamentals(
                            ticker, 
                            data_fields=['ticker', 'company', 'price', 'change', 'volume', 'market_cap']
                        )
                        if individual_data:
                            # å€‹åˆ¥å–å¾—ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
                            if hasattr(individual_data, 'ticker'):
                                etf_data = {
                                    'ticker': getattr(individual_data, 'ticker', ticker),
                                    'company': getattr(individual_data, 'company', ''),
                                    'price': getattr(individual_data, 'price', None),
                                    'change': getattr(individual_data, 'change', None),
                                    'volume': getattr(individual_data, 'volume', None),
                                    'market_cap': getattr(individual_data, 'market_cap', None)
                                }
                                logger.info(f"Successfully retrieved individual data for {ticker}")
                            else:
                                etf_data = individual_data
                        else:
                            etf_data = None
                    except Exception as individual_error:
                        logger.warning(f"Individual fetch also failed for {ticker}: {individual_error}")
                        etf_data = None
                    
                    # å€‹åˆ¥å–å¾—ãŒæˆåŠŸã—ãŸå ´åˆã€ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                    if etf_data and not etf_data.get('error'):
                        name = etf_names.get(ticker, ticker)
                        
                        # ãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ãªå–å¾—ï¼ˆå€‹åˆ¥å–å¾—ç‰ˆï¼‰
                        def get_safe_data_individual(key, default='N/A'):
                            value = etf_data.get(key, default)
                            return value if value is not None else default
                        
                        price = get_safe_data_individual('price')
                        change = get_safe_data_individual('change')
                        volume = get_safe_data_individual('volume')
                        market_cap = get_safe_data_individual('market_cap')
                        
                        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†
                        if isinstance(price, (int, float)):
                            price_str = f"${price:.2f}"
                        else:
                            price_str = str(price)
                        
                        # å¤‰å‹•ç‡ã®å‡¦ç†
                        if isinstance(change, str) and '%' in change:
                            change_str = change
                        elif isinstance(change, (int, float)):
                            change_str = f"{change:+.2f}%"
                        else:
                            change_str = str(change)
                        
                        # å‡ºæ¥é«˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                        if isinstance(volume, (int, float)):
                            volume_str = f"{int(volume):,}"
                        else:
                            volume_str = str(volume)
                        
                        # æ™‚ä¾¡ç·é¡ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ  
                        market_cap_str = str(market_cap) if market_cap != 'N/A' else 'N/A'
                        
                        # å¤‰å‹•æ–¹å‘ã®çµµæ–‡å­—
                        trend_emoji = "ğŸ“ˆ" if change_str.startswith('+') else "ğŸ“‰" if change_str.startswith('-') else "ğŸ“Š"
                        
                        output_lines.extend([
                            f"ğŸ”¹ {ticker} ({name}) [å€‹åˆ¥å–å¾—]",
                            f"   ğŸ’° ä¾¡æ ¼: {price_str}  {trend_emoji} å¤‰å‹•: {change_str}",
                            f"   ğŸ“¦ å‡ºæ¥é«˜: {volume_str}  ğŸ’¼ æ™‚ä¾¡ç·é¡: {market_cap_str}",
                            ""
                        ])
                    else:
                        # å…¨ã¦ã®å–å¾—æ–¹æ³•ãŒå¤±æ•—ã—ãŸå ´åˆ
                        name = etf_names.get(ticker, ticker)
                        error_msg = etf_data.get('error', 'ãƒ‡ãƒ¼ã‚¿ãªã—') if etf_data else 'ãƒ‡ãƒ¼ã‚¿ãªã—'
                        output_lines.extend([
                            f"ğŸ”¹ {ticker} ({name})",
                            f"   âš ï¸ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {error_msg}",
                            ""
                        ])
                    
            except Exception as e:
                logger.warning(f"Failed to process data for {ticker}: {e}")
                output_lines.extend([
                    f"ğŸ”¹ {ticker} ({etf_names.get(ticker, ticker)})",
                    f"   âš ï¸ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)[:30]}...",
                    ""
                ])
        
        # å¸‚å ´çµ±è¨ˆã®è¡¨ç¤º
        output_lines.extend([
            "ğŸ“Š å¸‚å ´æ´»å‹•çµ±è¨ˆ:",
            "-" * 50,
            f"ğŸ”¥ å‡ºæ¥é«˜æ€¥å¢—éŠ˜æŸ„æ•°: {volume_surge_count}éŠ˜æŸ„",
            f"ğŸ“ˆ ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰éŠ˜æŸ„æ•°: {uptrend_count}éŠ˜æŸ„", 
            f"ğŸ“‹ ä»Šé€±æ±ºç®—ç™ºè¡¨äºˆå®š: {earnings_count}éŠ˜æŸ„",
            ""
        ])
        
        # å‡ºæ¥é«˜æ€¥å¢—éŠ˜æŸ„ã®è©³ç´°çµ±è¨ˆ
        if volume_surge_count > 0:
            output_lines.extend([
                "ğŸ”¥ å‡ºæ¥é«˜æ€¥å¢—éŠ˜æŸ„è©³ç´°:",
                f"   ğŸ“Š å¹³å‡ç›¸å¯¾å‡ºæ¥é«˜: {avg_rel_vol:.1f}x",
                f"   ğŸ“ˆ å¹³å‡ä¾¡æ ¼å¤‰å‹•: +{avg_change:.1f}%",
                ""
            ])
        
        # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ä¸»è¦ã‚»ã‚¯ã‚¿ãƒ¼
        if top_sectors:
            output_lines.extend([
                "ğŸ“ˆ ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ä¸»è¦ã‚»ã‚¯ã‚¿ãƒ¼:",
            ])
            for sector, count in top_sectors.items():
                output_lines.append(f"   ğŸ¢ {sector}: {count}éŠ˜æŸ„")
            output_lines.append("")
        
        output_lines.extend([
            "=" * 70,
            "ğŸ’¡ è©³ç´°åˆ†æã«ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„:",
            "ğŸ” get_stock_fundamentals - å€‹åˆ¥éŠ˜æŸ„è©³ç´°ãƒ‡ãƒ¼ã‚¿",
            "ğŸ”¥ volume_surge_screener - å‡ºæ¥é«˜æ€¥å¢—éŠ˜æŸ„è©³ç´°",
            "ğŸ“ˆ uptrend_screener - ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰éŠ˜æŸ„è©³ç´°",
            "ğŸ¢ get_sector_performance - ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ",
            "",
            f"ğŸŒ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: Finviz Elite (https://elite.finviz.com/)",
            f"â° æœ€çµ‚æ›´æ–°: {pd.Timestamp.now().strftime('%H:%M:%S')}"
        ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in get_market_overview: {str(e)}")
        return [TextContent(type="text", text=f"âŒ å¸‚å ´æ¦‚è¦ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")]

@server.tool()
def get_relative_volume_stocks(
    min_relative_volume: Any,
    min_price: Optional[Union[int, float, str]] = None,
    sectors: Optional[List[str]] = None,
    max_results: int = 50
) -> List[TextContent]:
    """
    ç›¸å¯¾å‡ºæ¥é«˜ç•°å¸¸éŠ˜æŸ„ã®æ¤œå‡º
    
    Args:
        min_relative_volume: æœ€ä½ç›¸å¯¾å‡ºæ¥é«˜
        min_price: æœ€ä½æ ªä¾¡
        sectors: å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼
        max_results: æœ€å¤§å–å¾—ä»¶æ•°
    """
    try:
        # Build screening parameters
        params = {
            'min_relative_volume': min_relative_volume,
            'min_price': min_price,
            'sectors': sectors or [],
            'max_results': max_results or 50
        }
        
        # Use volume surge screener as the base
        results = finviz_screener.screen_stocks({
            'relative_volume_min': min_relative_volume,
            'price_min': min_price,
            'sectors': sectors or []
        })
        
        # Sort by relative volume
        results.sort(key=lambda x: x.relative_volume or 0, reverse=True)
        results = results[:max_results or 50]
        
        if not results:
            return [TextContent(type="text", text=f"No stocks found with relative volume >= {min_relative_volume}x.")]
        
        # Format output
        output_lines = [
            f"High Relative Volume Stocks (>= {min_relative_volume}x):",
            "=" * 60,
            ""
        ]
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        output_lines.extend([
            f"{'Ticker':<8} {'Company':<25} {'Price':<8} {'Change%':<8} {'Volume':<12} {'Rel Vol':<8}",
            "-" * 70
        ])
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for stock in results:
            company_short = (stock.company_name[:22] + "...") if stock.company_name and len(stock.company_name) > 25 else (stock.company_name or "N/A")
            
            output_lines.append(
                f"{stock.ticker:<8} "
                f"{company_short:<25} "
                f"${stock.price:<7.2f} " if stock.price else f"{'N/A':<8} "
                f"{stock.price_change:>7.2f}% " if stock.price_change else f"{'N/A':<8} "
                f"{stock.volume:>11,} " if stock.volume else f"{'N/A':<12} "
                f"{stock.relative_volume:>7.2f}x" if stock.relative_volume else f"{'N/A':<8}"
            )
        
        output_lines.extend([
            "",
            f"Found {len(results)} stocks with unusual volume activity."
        ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in get_relative_volume_stocks: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def technical_analysis_screener(
    rsi_min: Optional[Union[int, float, str]] = None,
    rsi_max: Optional[Union[int, float, str]] = None,
    price_vs_sma20: Optional[str] = None,
    price_vs_sma50: Optional[str] = None,
    price_vs_sma200: Optional[str] = None,
    min_price: Optional[Union[int, float, str]] = None,
    min_volume: Optional[int] = None,
    sectors: Optional[List[str]] = None,
    max_results: int = 50
) -> List[TextContent]:
    """
    ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    
    Args:
        rsi_min: RSIæœ€ä½å€¤
        rsi_max: RSIæœ€é«˜å€¤
        price_vs_sma20: 20æ—¥ç§»å‹•å¹³å‡ã¨ã®é–¢ä¿‚ (above, below)
        price_vs_sma50: 50æ—¥ç§»å‹•å¹³å‡ã¨ã®é–¢ä¿‚ (above, below)
        price_vs_sma200: 200æ—¥ç§»å‹•å¹³å‡ã¨ã®é–¢ä¿‚ (above, below)
        min_price: æœ€ä½æ ªä¾¡
        min_volume: æœ€ä½å‡ºæ¥é«˜
        sectors: å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼
        max_results: æœ€å¤§å–å¾—ä»¶æ•°
    """
    try:
        # Build screening parameters
        filters = {}
        
        if rsi_min is not None:
            filters['rsi_min'] = rsi_min
        if rsi_max is not None:
            filters['rsi_max'] = rsi_max
        if price_vs_sma20 == "above":
            filters['sma20_above'] = True
        elif price_vs_sma20 == "below":
            filters['sma20_below'] = True
        if price_vs_sma50 == "above":
            filters['sma50_above'] = True
        elif price_vs_sma50 == "below":
            filters['sma50_below'] = True
        if price_vs_sma200 == "above":
            filters['sma200_above'] = True
        elif price_vs_sma200 == "below":
            filters['sma200_below'] = True
        if min_price is not None:
            filters['price_min'] = min_price
        if min_volume is not None:
            filters['volume_min'] = min_volume
        if sectors:
            filters['sectors'] = sectors
        
        results = finviz_screener.screen_stocks(filters)
        results = results[:max_results or 50]
        
        if not results:
            return [TextContent(type="text", text="No stocks found matching technical criteria.")]
        
        # Format output
        criteria_text = []
        if rsi_min is not None and rsi_max is not None:
            criteria_text.append(f"RSI: {rsi_min}-{rsi_max}")
        elif rsi_min is not None:
            criteria_text.append(f"RSI >= {rsi_min}")
        elif rsi_max is not None:
            criteria_text.append(f"RSI <= {rsi_max}")
        
        if price_vs_sma20:
            criteria_text.append(f"Price {price_vs_sma20} SMA20")
        if price_vs_sma50:
            criteria_text.append(f"Price {price_vs_sma50} SMA50")
        if price_vs_sma200:
            criteria_text.append(f"Price {price_vs_sma200} SMA200")
        
        output_lines = [
            f"Technical Analysis Screening Results:",
            f"Criteria: {', '.join(criteria_text) if criteria_text else 'All stocks'}",
            "=" * 60,
            ""
        ]
        
        for stock in results:
            output_lines.extend([
                f"Ticker: {stock.ticker}",
                f"Company: {stock.company_name}",
                f"Sector: {stock.sector}",
                f"Price: ${stock.price:.2f}" if stock.price else "Price: N/A",
                f"RSI: {stock.rsi:.2f}" if stock.rsi else "RSI: N/A",
                f"SMA 20: ${stock.sma_20:.2f}" if stock.sma_20 else "SMA 20: N/A",
                f"SMA 50: ${stock.sma_50:.2f}" if stock.sma_50 else "SMA 50: N/A",
                f"SMA 200: ${stock.sma_200:.2f}" if stock.sma_200 else "SMA 200: N/A",
                f"Volume: {stock.volume:,}" if stock.volume else "Volume: N/A",
                "-" * 40,
                ""
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in technical_analysis_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

def cli_main():
    """CLI entry point"""
    server.run()

@server.tool()
def earnings_winners_screener(
    earnings_period: Optional[str] = "this_week",
    market_cap: Optional[str] = "smallover",
    min_price: Optional[Union[int, float, str]] = 10.0,
    min_avg_volume: Optional[str] = "o500",
    min_eps_growth_qoq: Optional[float] = 10.0,
    min_eps_revision: Optional[float] = 5.0,
    min_sales_growth_qoq: Optional[float] = 5.0,
    min_weekly_performance: Optional[str] = "5to-1w",
    sma200_filter: Optional[bool] = True,
    target_sectors: Optional[List[str]] = None,
    max_results: int = 50,
    sort_by: Optional[str] = "performance_1w",
    sort_order: Optional[str] = "desc"
) -> List[TextContent]:
    """
    æ±ºç®—å‹ã¡çµ„éŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° - é€±é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€EPSã‚µãƒ—ãƒ©ã‚¤ã‚ºã€å£²ä¸Šã‚µãƒ—ãƒ©ã‚¤ã‚ºã‚’å«ã‚€è©³ç´°ä¸€è¦§
    
    Finviz URLã¨åŒä¸€ã®æ¡ä»¶ãƒ»ãƒ‡ãƒ¼ã‚¿ã§æ±ºç®—å¾Œã«ä¸Šæ˜‡ã—ãŸéŠ˜æŸ„ã‚’æ¤œç´¢ã—ã€è¡¨å½¢å¼ã§è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
    å–å¾—ãƒ‡ãƒ¼ã‚¿ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ï¼š
    - é€±é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆPerformance Weekï¼‰
    - EPSã‚µãƒ—ãƒ©ã‚¤ã‚ºï¼ˆEPS Surpriseï¼‰
    - å£²ä¸Šã‚µãƒ—ãƒ©ã‚¤ã‚ºï¼ˆRevenue Surpriseï¼‰
    - EPSå‰å››åŠæœŸæ¯”æˆé•·ç‡ï¼ˆEPS QoQ Growthï¼‰
    - å£²ä¸Šå‰å››åŠæœŸæ¯”æˆé•·ç‡ï¼ˆSales QoQ Growthï¼‰
    - åŸºæœ¬çš„ãªæ ªä¾¡ãƒ»å‡ºæ¥é«˜ãƒ‡ãƒ¼ã‚¿
    
    Args:
        earnings_period: æ±ºç®—ç™ºè¡¨æœŸé–“ ('this_week', 'yesterday', 'today', 'custom')
        market_cap: æ™‚ä¾¡ç·é¡ãƒ•ã‚£ãƒ«ã‚¿ ('small', 'mid', 'large', 'mega', 'smallover')
        min_price: æœ€ä½æ ªä¾¡ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: $10)
        min_avg_volume: æœ€ä½å¹³å‡å‡ºæ¥é«˜ (æ•°å€¤ã¾ãŸã¯æ–‡å­—åˆ—å½¢å¼ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "o500" = 500,000ä»¥ä¸Š)
        min_eps_growth_qoq: æœ€ä½EPSå‰å››åŠæœŸæ¯”æˆé•·ç‡(%) (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10%)
        min_eps_revision: æœ€ä½EPSäºˆæƒ³æ”¹è¨‚ç‡(%) (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5%)
        min_sales_growth_qoq: æœ€ä½å£²ä¸Šå‰å››åŠæœŸæ¯”æˆé•·ç‡(%) (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5%)
        min_weekly_performance: é€±æ¬¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5to-1w)
        sma200_filter: 200æ—¥ç§»å‹•å¹³å‡ç·šä¸Šã®ãƒ•ã‚£ãƒ«ã‚¿ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: True)
        target_sectors: å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä¸»è¦6ã‚»ã‚¯ã‚¿ãƒ¼)
        max_results: æœ€å¤§å–å¾—ä»¶æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50)
        sort_by: ã‚½ãƒ¼ãƒˆåŸºæº– ('performance_1w', 'eps_growth_qoq', 'eps_surprise', 'price_change', 'volume')
        sort_order: ã‚½ãƒ¼ãƒˆé †åº ('asc', 'desc')
    
    Returns:
        æ±ºç®—å‹ã¡çµ„éŠ˜æŸ„ã®è©³ç´°ä¸€è¦§ï¼ˆè¡¨å½¢å¼ + åˆ†æãƒ‡ãƒ¼ã‚¿ + Finviz URLï¼‰
        - ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«: éŠ˜æŸ„ | ä¼æ¥­å | ã‚»ã‚¯ã‚¿ãƒ¼ | æ ªä¾¡ | é€±é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ | EPSã‚µãƒ—ãƒ©ã‚¤ã‚º | å£²ä¸Šã‚µãƒ—ãƒ©ã‚¤ã‚º | æ±ºç®—æ—¥
        - ä¸Šä½5éŠ˜æŸ„ã®è©³ç´°åˆ†æ
        - EPSã‚µãƒ—ãƒ©ã‚¤ã‚ºçµ±è¨ˆ
        - ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        - å…ƒãƒ‡ãƒ¼ã‚¿ã®Finviz URLï¼ˆCSV exportå½¢å¼ï¼‰
    """
    try:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æº–å‚™
        params = {
            'earnings_period': earnings_period,
            'market_cap': market_cap,
            'min_price': min_price,
            'min_avg_volume': min_avg_volume,
            'min_eps_growth_qoq': min_eps_growth_qoq,
            'min_eps_revision': min_eps_revision,
            'min_sales_growth_qoq': min_sales_growth_qoq,
            'min_weekly_performance': min_weekly_performance,
            'sma200_filter': sma200_filter,
            'max_results': max_results,
            'sort_by': sort_by,
            'sort_order': sort_order
        }
        
        # ã‚»ã‚¯ã‚¿ãƒ¼è¨­å®š
        if target_sectors:
            params['target_sectors'] = target_sectors
        else:
            params['target_sectors'] = [
                "Technology", "Industrials", "Healthcare", 
                "Communication Services", "Consumer Cyclical", "Financial Services"
            ]
        
        # earnings_dateãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
        if earnings_period == 'this_week':
            params['earnings_date'] = 'thisweek'
        elif earnings_period == 'yesterday':
            params['earnings_date'] = 'yesterday'
        elif earnings_period == 'today':
            params['earnings_date'] = 'today'
        else:
            params['earnings_date'] = 'thisweek'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        logger.info(f"Executing earnings winners screening with params: {params}")
        
        # ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        try:
            results = finviz_screener.earnings_winners_screener(**params)
        except Exception as e:
            logger.warning(f"earnings_winners_screener failed, trying earnings_screener: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: earnings_screenerãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
            fallback_params = {
                'earnings_date': params.get('earnings_date', 'thisweek'),
                'market_cap': params.get('market_cap', 'smallover'),
                'min_price': params.get('min_price'),
                'sectors': params.get('target_sectors')
            }
            fallback_params = {k: v for k, v in fallback_params.items() if v is not None}
            results = finviz_screener.earnings_screener(**fallback_params)
        
        if not results:
            return [TextContent(type="text", text="No earnings winners found matching the criteria.")]
        
        # çµæœã®è¡¨ç¤º
        output_lines = _format_earnings_winners_list(results, params)
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in earnings_winners_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def upcoming_earnings_screener(
    earnings_period: Optional[str] = "next_week",
    market_cap: Optional[str] = "smallover",
    min_price: Optional[Union[int, float, str]] = 10,
    min_avg_volume: Optional[str] = "o500",  # Support both numeric and string values - converts internally
    target_sectors: Optional[List[str]] = None,
    pre_earnings_analysis: Optional[Dict[str, Any]] = None,
    risk_assessment: Optional[Dict[str, Any]] = None,
    data_fields: Optional[List[str]] = None,
    max_results: int = 100,
    sort_by: Optional[str] = "earnings_date",
    sort_order: Optional[str] = "asc",
    include_chart_view: Optional[bool] = True,
    earnings_calendar_format: Optional[bool] = False,
    custom_date_range: Optional[str] = None,  # æ–°æ©Ÿèƒ½: ã‚«ã‚¹ã‚¿ãƒ æ—¥ä»˜ç¯„å›² (ä¾‹: "06-30-2025x07-04-2025")
    start_date: Optional[str] = None,  # æ–°æ©Ÿèƒ½: é–‹å§‹æ—¥ (YYYY-MM-DD format)
    end_date: Optional[str] = None     # æ–°æ©Ÿèƒ½: çµ‚äº†æ—¥ (YYYY-MM-DD format)
) -> List[TextContent]:
    """
    æ¥é€±æ±ºç®—äºˆå®šéŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæ±ºç®—ãƒˆãƒ¬ãƒ¼ãƒ‰äº‹å‰æº–å‚™ç”¨ï¼‰
    
    Args:
        earnings_period: æ±ºç®—ç™ºè¡¨æœŸé–“ ('next_week', 'next_2_weeks', 'next_month', 'custom_range')
        market_cap: æ™‚ä¾¡ç·é¡ãƒ•ã‚£ãƒ«ã‚¿ ('small', 'mid', 'large', 'mega', 'smallover')
        min_price: æœ€ä½æ ªä¾¡
        min_avg_volume: æœ€ä½å¹³å‡å‡ºæ¥é«˜
        target_sectors: å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼ï¼ˆ8ã‚»ã‚¯ã‚¿ãƒ¼ï¼‰
        pre_earnings_analysis: æ±ºç®—å‰åˆ†æé …ç›®ã®è¨­å®š
        risk_assessment: ãƒªã‚¹ã‚¯è©•ä¾¡é …ç›®ã®è¨­å®š
        data_fields: å–å¾—ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        max_results: æœ€å¤§å–å¾—ä»¶æ•°
        sort_by: ã‚½ãƒ¼ãƒˆåŸºæº– ('earnings_date', 'market_cap', 'target_price_upside', 'volatility', 'earnings_potential_score')
        sort_order: ã‚½ãƒ¼ãƒˆé †åº ('asc', 'desc')
        include_chart_view: é€±è¶³ãƒãƒ£ãƒ¼ãƒˆãƒ“ãƒ¥ãƒ¼ã‚’å«ã‚ã‚‹
        earnings_calendar_format: æ±ºç®—ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å½¢å¼ã§å‡ºåŠ›
        custom_date_range: ã‚«ã‚¹ã‚¿ãƒ æ—¥ä»˜ç¯„å›²ï¼ˆFinvizå½¢å¼: "MM-DD-YYYYxMM-DD-YYYY"ï¼‰
        start_date: é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ã€end_dateã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ï¼‰
        end_date: çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ã€start_dateã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ï¼‰
    
    Returns:
        æ¥é€±æ±ºç®—äºˆå®šéŠ˜æŸ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœ
    """
    try:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æº–å‚™ã¨æ­£è¦åŒ–
        params = {
            'earnings_period': earnings_period,
            'market_cap': market_cap,
            'min_price': min_price,
            'max_results': max_results,
            'sort_by': sort_by,
            'sort_order': sort_order
        }
        
        # å‡ºæ¥é«˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ­£è¦åŒ– - æ•°å€¤ã¨æ–‡å­—åˆ—ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆ
        if min_avg_volume is not None:
            if isinstance(min_avg_volume, (int, float)):
                # æ•°å€¤ã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
                params['avg_volume_min'] = min_avg_volume
            elif isinstance(min_avg_volume, str):
                # æ–‡å­—åˆ—ã®å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å€¤ã¨ã—ã¦ä½¿ç”¨
                params['average_volume'] = min_avg_volume
        
        # ã‚»ã‚¯ã‚¿ãƒ¼ã®æ­£è¦åŒ– - upcoming_earnings_screenã§ä½¿ç”¨ã•ã‚Œã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã«åˆã‚ã›ã‚‹
        if target_sectors:
            params['target_sectors'] = target_sectors
        else:
            params['target_sectors'] = [
                "Technology", "Industrials", "Healthcare", "Communication Services",
                "Consumer Cyclical", "Financial Services", "Consumer Defensive", "Basic Materials"
            ]
        
        # æ±ºç®—å‰åˆ†æé …ç›®ã®è¨­å®š
        if pre_earnings_analysis:
            params.update(pre_earnings_analysis)
        
        # ãƒªã‚¹ã‚¯è©•ä¾¡é …ç›®ã®è¨­å®š
        if risk_assessment:
            params.update(risk_assessment)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è¨­å®šã¯ç„¡è¦–ï¼ˆæ–°å®Ÿè£…ã§ã¯ä¸è¦ï¼‰
        
        # earnings_dateãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®šï¼ˆå„ªå…ˆé †ä½é †ï¼‰
        # 1. ã‚«ã‚¹ã‚¿ãƒ æ—¥ä»˜ç¯„å›²ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
        if custom_date_range:
            params['earnings_date'] = custom_date_range
        # 2. é–‹å§‹æ—¥ã¨çµ‚äº†æ—¥ãŒä¸¡æ–¹æŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
        elif start_date and end_date:
            params['earnings_date'] = {'start': start_date, 'end': end_date}
        # 3. å¾“æ¥ã®æœŸé–“æŒ‡å®š
        elif earnings_period == 'next_week':
            params['earnings_date'] = 'nextweek'
        elif earnings_period == 'next_2_weeks':
            params['earnings_date'] = 'nextdays5'
        elif earnings_period == 'next_month':
            params['earnings_date'] = 'thismonth'
        else:
            params['earnings_date'] = 'nextweek'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ - æ–°ã—ã„advanced_screenãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
        logger.info(f"Executing upcoming earnings screening with params: {params}")
        logger.info(f"Final earnings_date parameter: {params.get('earnings_date')}")
        # upcoming_earnings_screenãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
        try:
            results = finviz_screener.upcoming_earnings_screener(**params)
        except Exception as e:
            logger.warning(f"upcoming_earnings_screen failed, trying earnings_screen: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: earnings_screenãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
            fallback_params = {
                'earnings_date': params.get('earnings_date', 'nextweek'),
                'market_cap': params.get('market_cap', 'smallover'),
                'min_price': params.get('min_price'),
                'sectors': params.get('target_sectors')
            }
            # Noneå€¤ã‚’é™¤å»
            fallback_params = {k: v for k, v in fallback_params.items() if v is not None}
            results = finviz_screener.earnings_screener(**fallback_params)
        
        if not results:
            return [TextContent(type="text", text="No upcoming earnings stocks found.")]
        
        # çµæœã®è¡¨ç¤º
        if earnings_calendar_format:
            output_lines = _format_earnings_calendar(results, include_chart_view)
        else:
            output_lines = _format_upcoming_earnings_list(results, include_chart_view)
        
        # Finviz CSVåˆ¶é™ã«ã¤ã„ã¦ã®æ³¨æ„æ›¸ãã‚’è¿½åŠ 
        output_lines.extend([
            "",
            "ğŸ“‹ Note: Finviz CSV export does not include earnings date information in the response,",
            "    even when filtering by earnings date. The stocks above match your earnings date",
            f"    criteria ({earnings_period}) but specific dates are not shown in the CSV data.",
            "    For exact earnings dates, please check the Finviz website directly.",
            "",
            f"ğŸ”— Finviz URL with your filters:",
            f"    {_generate_finviz_url(market_cap, params.get('earnings_date', 'nextweek'))}"
        ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except Exception as e:
        logger.error(f"Error in upcoming_earnings_screener: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

def _format_earnings_winners_list(results: List, params: Dict[str, Any]) -> List[str]:
    """æ±ºç®—å¾Œä¸Šæ˜‡éŠ˜æŸ„ã‚’ãƒªã‚¹ãƒˆå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    output_lines = [
        f"ğŸ“ˆ æ±ºç®—å‹ã¡çµ„éŠ˜æŸ„ä¸€è¦§ - Weeklyãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨EPSã‚µãƒ—ãƒ©ã‚¤ã‚º",
        "",
        f"ğŸ¯ ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶:",
        f"- æ±ºç®—ç™ºè¡¨æœŸé–“: {params.get('earnings_period', 'this_week')}",
        f"- æ™‚ä¾¡ç·é¡: {params.get('market_cap', 'smallover')} ($300M+)", 
        f"- æœ€ä½æ ªä¾¡: ${params.get('min_price', 10):.1f}",
        f"- æœ€ä½å¹³å‡å‡ºæ¥é«˜: {params.get('min_avg_volume', 'o500')}",
        f"- æœ€ä½EPS QoQæˆé•·ç‡: {params.get('min_eps_growth_qoq', 10)}%+",
        f"- æœ€ä½EPSäºˆæƒ³æ”¹è¨‚: {params.get('min_eps_revision', 5)}%+",
        f"- æœ€ä½å£²ä¸ŠQoQæˆé•·ç‡: {params.get('min_sales_growth_qoq', 5)}%+",
        f"- SMA200ä¸Š: {params.get('sma200_filter', True)}",
        "",
        "=" * 120,
        ""
    ]
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼
    output_lines.extend([
        "| éŠ˜æŸ„    | ä¼æ¥­å                              | ã‚»ã‚¯ã‚¿ãƒ¼        | æ ªä¾¡    | é€±é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ | EPSã‚µãƒ—ãƒ©ã‚¤ã‚º | å£²ä¸Šã‚µãƒ—ãƒ©ã‚¤ã‚º | æ±ºç®—æ—¥      |",
        "|---------|-------------------------------------|-----------------|---------|-------------------|---------------|---------------|-------------|"
    ])
    
    for stock in results:
        # ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†
        ticker = stock.ticker or "N/A"
        company = (stock.company_name or "N/A")[:35]  # 35æ–‡å­—ã«åˆ¶é™
        sector = (stock.sector or "N/A")[:15]  # 15æ–‡å­—ã«åˆ¶é™
        price = f"${stock.price:.2f}" if stock.price else "N/A"
        
        # é€±é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        weekly_perf = f"+{stock.performance_1w:.1f}%" if stock.performance_1w else "N/A"
        
        # EPSã‚µãƒ—ãƒ©ã‚¤ã‚º
        eps_surprise = f"+{stock.eps_surprise:.1f}%" if stock.eps_surprise else "N/A"
        
        # å£²ä¸Šã‚µãƒ—ãƒ©ã‚¤ã‚º
        revenue_surprise = f"+{stock.revenue_surprise:.1f}%" if stock.revenue_surprise else "N/A"
        
        # æ±ºç®—æ—¥
        earnings_date = stock.earnings_date or "N/A"
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‚’ä½œæˆ
        row = f"| {ticker:<7} | {company:<35} | {sector:<15} | {price:<7} | {weekly_perf:>17} | {eps_surprise:>13} | {revenue_surprise:>13} | {earnings_date:<11} |"
        output_lines.append(row)
    
    output_lines.extend([
        "",
        "=" * 120,
        "",
        "ğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ:",
        ""
    ])
    
    # ä¸Šä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®è©³ç´°åˆ†æ
    if results:
        top_performers = sorted([s for s in results if s.performance_1w], 
                               key=lambda x: x.performance_1w, reverse=True)[:5]
        
        output_lines.append("ğŸ“ˆ é€±é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šä½5éŠ˜æŸ„:")
        for i, stock in enumerate(top_performers, 1):
            output_lines.extend([
                f"",
                f"ğŸ† #{i} **{stock.ticker}** - {stock.company_name}",
                f"   ğŸ“Š é€±é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: **+{stock.performance_1w:.1f}%**",
                f"   ğŸ’° æ ªä¾¡: ${stock.price:.2f}" if stock.price else "   ğŸ’° æ ªä¾¡: N/A",
                f"   ğŸ¯ EPSã‚µãƒ—ãƒ©ã‚¤ã‚º: {stock.eps_surprise:.1f}%" if stock.eps_surprise else "   ğŸ¯ EPSã‚µãƒ—ãƒ©ã‚¤ã‚º: N/A",
                f"   ğŸ“ˆ å£²ä¸Šã‚µãƒ—ãƒ©ã‚¤ã‚º: {stock.revenue_surprise:.1f}%" if stock.revenue_surprise else "   ğŸ“ˆ å£²ä¸Šã‚µãƒ—ãƒ©ã‚¤ã‚º: N/A",
                f"   ğŸ¢ ã‚»ã‚¯ã‚¿ãƒ¼: {stock.sector}",
                f"   ğŸ“… æ±ºç®—æ—¥: {stock.earnings_date}" if stock.earnings_date else "   ğŸ“… æ±ºç®—æ—¥: N/A"
            ])
            
            # è¿½åŠ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics = []
            if stock.eps_qoq_growth or stock.eps_growth_qtr:
                eps_growth = stock.eps_qoq_growth or stock.eps_growth_qtr
                metrics.append(f"EPS QoQ: {eps_growth:.1f}%")
            if stock.sales_qoq_growth or stock.sales_growth_qtr:
                sales_growth = stock.sales_qoq_growth or stock.sales_growth_qtr
                metrics.append(f"å£²ä¸ŠQoQ: {sales_growth:.1f}%")
            if stock.volume and stock.avg_volume and stock.avg_volume > 0:
                rel_vol = stock.volume / stock.avg_volume
                metrics.append(f"ç›¸å¯¾å‡ºæ¥é«˜: {rel_vol:.1f}x")
            if stock.pe_ratio:
                metrics.append(f"PER: {stock.pe_ratio:.1f}")
                
            if metrics:
                output_lines.append(f"   ğŸ“‹ è²¡å‹™æŒ‡æ¨™: {' | '.join(metrics)}")
    
    # ã‚µãƒ—ãƒ©ã‚¤ã‚ºåˆ†æ
    surprise_stocks = [s for s in results if s.eps_surprise and s.eps_surprise > 0]
    if surprise_stocks:
        avg_eps_surprise = sum(s.eps_surprise for s in surprise_stocks) / len(surprise_stocks)
        max_eps_surprise = max(s.eps_surprise for s in surprise_stocks)
        
        output_lines.extend([
            "",
            "ğŸ¯ EPSã‚µãƒ—ãƒ©ã‚¤ã‚ºåˆ†æ:",
            f"   â€¢ å¹³å‡EPSã‚µãƒ—ãƒ©ã‚¤ã‚º: {avg_eps_surprise:.1f}%",
            f"   â€¢ æœ€å¤§EPSã‚µãƒ—ãƒ©ã‚¤ã‚º: {max_eps_surprise:.1f}%",
            f"   â€¢ ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚µãƒ—ãƒ©ã‚¤ã‚ºéŠ˜æŸ„æ•°: {len(surprise_stocks)}ä»¶"
        ])
    
    # ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æ
    sector_performance = {}
    for stock in results:
        if stock.sector and stock.performance_1w:
            if stock.sector not in sector_performance:
                sector_performance[stock.sector] = []
            sector_performance[stock.sector].append(stock.performance_1w)
    
    if sector_performance:
        output_lines.extend([
            "",
            "ğŸ¢ ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:",
        ])
        
        for sector, performances in sector_performance.items():
            avg_perf = sum(performances) / len(performances)
            count = len(performances)
            output_lines.append(f"   â€¢ {sector}: å¹³å‡ {avg_perf:.1f}% ({count}éŠ˜æŸ„)")
    
    # Finviz URLã‚’è¿½åŠ 
    earnings_date_param = params.get('earnings_date', 'thisweek')
    market_cap_param = params.get('market_cap', 'smallover')
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
    import os
    api_key = os.getenv('FINVIZ_API_KEY', 'YOUR_API_KEY_HERE')
    
    finviz_url = f"https://elite.finviz.com/export.ashx?v=151&f=cap_{market_cap_param},earningsdate_{earnings_date_param},fa_epsqoq_o{int(params.get('min_eps_growth_qoq', 10))},fa_epsrev_eo{int(params.get('min_eps_revision', 5))},fa_salesqoq_o{int(params.get('min_sales_growth_qoq', 5))},sec_technology|industrials|healthcare|communicationservices|consumercyclical|financial,sh_avgvol_{params.get('min_avg_volume', 'o500')},sh_price_o{int(params.get('min_price', 10))},ta_perf_{params.get('min_weekly_performance', '5to-1w')},ta_sma200_pa&ft=4&o=ticker&ar={params.get('max_results', 50)}&c=0,1,2,79,3,4,5,6,7,8,9,10,11,12,13,73,74,75,14,15,16,77,17,18,19,20,21,23,22,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,90,91,92,93,94,95,96,97,98,99,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,80,83,76,60,61,62,63,64,67,89,69,81,86,87,88,65,66,71,72,103,100,101,104,102,106,107,108,109,110,125,126,59,68,70,111,112,113,114,115,116,117,118,119,120,121,122,123,124,105&auth={api_key}"
    
    output_lines.extend([
        "",
        "ğŸ”— åŒä¸€çµæœã‚’Finvizã§ç¢ºèª:",
        f"   {finviz_url}",
        "",
        "ğŸ’¡ ã“ã‚Œã‚‰ã®éŠ˜æŸ„ã¯æœ€è¿‘æ±ºç®—ã‚’ç™ºè¡¨ã—ã€å¼·ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨è‰¯å¥½ãªãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«æŒ‡æ¨™ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚",
        "   ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ å–å¼•ã‚„è©³ç´°åˆ†æã®å¯¾è±¡ã¨ã—ã¦æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
    ])
    
    return output_lines

def _generate_finviz_url(market_cap: str, earnings_date) -> str:
    """Finviz URLã‚’ç”Ÿæˆ"""
    base_url = "https://elite.finviz.com/screener.ashx?v=311&f="
    
    # Market cap filter
    cap_filter = f"cap_{market_cap or 'smallover'}"
    
    # Earnings date filter
    if isinstance(earnings_date, dict):
        # è¾æ›¸å½¢å¼ã®å ´åˆï¼ˆstart/endï¼‰
        from .finviz_client.base import FinvizClient
        client = FinvizClient()
        start_formatted = client._format_date_for_finviz(earnings_date['start'])
        end_formatted = client._format_date_for_finviz(earnings_date['end'])
        earnings_filter = f"earningsdate_{start_formatted}x{end_formatted}"
    elif isinstance(earnings_date, str) and 'x' in earnings_date:
        # æ—¥ä»˜ç¯„å›²æ–‡å­—åˆ—ã®å ´åˆ
        earnings_filter = f"earningsdate_{earnings_date}"
    else:
        # å›ºå®šæœŸé–“ã®å ´åˆ
        earnings_filter = f"earningsdate_{earnings_date}"
    
    return f"{base_url}{cap_filter},{earnings_filter}"

def _format_upcoming_earnings_list(results: List, include_chart_view: bool = True) -> List[str]:
    """æ¥é€±æ±ºç®—äºˆå®šéŠ˜æŸ„ã‚’ãƒªã‚¹ãƒˆå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    output_lines = [
        f"Upcoming Earnings Screening Results ({len(results)} stocks found):",
        "=" * 70,
        ""
    ]
    
    for stock in results:
        output_lines.extend([
            f"ğŸ“ˆ {stock.ticker} - {stock.company_name}",
            f"   Sector: {stock.sector} | Industry: {stock.industry}",
            f"   Earnings Date: {stock.earnings_date or 'Not available in CSV'} | Timing: {stock.earnings_timing or 'N/A'}",
            f"   Current Price: ${stock.current_price:.2f}" if stock.current_price else "   Current Price: N/A",
            f"   Market Cap: {format_large_number(stock.market_cap)}" if stock.market_cap else "   Market Cap: N/A",
            f"   PE Ratio: {stock.pe_ratio:.2f}" if stock.pe_ratio else "   PE Ratio: N/A",
            f"   Target Price: ${stock.target_price:.2f}" if stock.target_price else "   Target Price: N/A",
            f"   Target Upside: {stock.target_price_upside:.1f}%" if stock.target_price_upside else "   Target Upside: N/A",
            f"   Analyst Recommendation: {stock.analyst_recommendation}" if stock.analyst_recommendation else "   Analyst Recommendation: N/A",
            f"   Volatility: {stock.volatility:.2f}" if stock.volatility else "   Volatility: N/A",
            f"   Short Interest: {stock.short_interest:.1f}%" if stock.short_interest else "   Short Interest: N/A",
            f"   Avg Volume: {format_large_number(stock.avg_volume)}" if stock.avg_volume else "   Avg Volume: N/A",
            ""
        ])
        
        # Additional metrics (if available)
        additional_metrics = []
        if stock.performance_1w is not None:
            additional_metrics.append(f"   â€¢ 1W Performance: {stock.performance_1w:.1f}%")
        if stock.performance_1m is not None:
            additional_metrics.append(f"   â€¢ 1M Performance: {stock.performance_1m:.1f}%")
        if stock.rsi is not None:
            additional_metrics.append(f"   â€¢ RSI: {stock.rsi:.1f}")
        
        if additional_metrics:
            output_lines.extend([
                "   ğŸ“Š Additional Metrics:",
                *additional_metrics,
                ""
            ])
        
        output_lines.append("-" * 70)
        output_lines.append("")
    
    return output_lines

def _format_earnings_calendar(results: List, include_chart_view: bool = True) -> List[str]:
    """æ¥é€±æ±ºç®—äºˆå®šéŠ˜æŸ„ã‚’ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    output_lines = [
        f"ğŸ“… Upcoming Earnings Calendar ({len(results)} stocks)",
        "=" * 70,
        ""
    ]
    
    # æ—¥ä»˜ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    by_date = {}
    for stock in results:
        date = stock.earnings_date or "Unknown"
        if date not in by_date:
            by_date[date] = []
        by_date[date].append(stock)
    
    # æ—¥ä»˜é †ã§ã‚½ãƒ¼ãƒˆ
    for date in sorted(by_date.keys()):
        stocks = by_date[date]
        output_lines.extend([
            f"ğŸ“… {date}",
            "-" * 30,
            ""
        ])
        
        for stock in stocks:
            upside_str = f"(+{stock.target_price_upside:.1f}%)" if stock.target_price_upside and stock.target_price_upside > 0 else ""
            output_lines.extend([
                f"  â€¢ {stock.ticker} - {stock.company_name}",
                f"    ${stock.current_price:.2f} â†’ ${stock.target_price:.2f} {upside_str}" if stock.current_price and stock.target_price else f"    Current: ${stock.current_price:.2f}" if stock.current_price else "    Price: N/A",
                f"    {stock.sector} | PE: {stock.pe_ratio:.1f}" if stock.pe_ratio else f"    {stock.sector}",
                ""
            ])
        
        output_lines.append("")
    
    return output_lines

def _format_earnings_premarket_list(results: List, params: Dict[str, Any]) -> List[str]:
    """å¯„ã‚Šä»˜ãå‰æ±ºç®—ä¸Šæ˜‡éŠ˜æŸ„ã®è©³ç´°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    def format_large_number(num):
        if not num:
            return "N/A"
        if num >= 1_000_000_000:
            return f"{num/1_000_000_000:.1f}B"
        elif num >= 1_000_000:
            return f"{num/1_000_000:.1f}M"
        elif num >= 1_000:
            return f"{num/1_000:.1f}K"
        else:
            return f"{num:.0f}"
    
    output_lines = [
        "ğŸ” å¯„ã‚Šä»˜ãå‰æ±ºç®—ä¸Šæ˜‡éŠ˜æŸ„ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœ",
        f"ğŸ“Š æ¤œå‡ºéŠ˜æŸ„æ•°: {len(results)}",
        "=" * 100,
        "",
        "ğŸ“‹ é©ç”¨ã•ã‚ŒãŸã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶:",
        f"   â€¢ æ™‚ä¾¡ç·é¡: {params.get('market_cap', 'smallover')} (ã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Š)",
        f"   â€¢ æ±ºç®—ã‚¿ã‚¤ãƒŸãƒ³ã‚°: {params.get('earnings_timing', 'today_before')} (ä»Šæ—¥ã®å¯„ã‚Šä»˜ãå‰)",
        f"   â€¢ æœ€ä½ä¾¡æ ¼: ${params.get('min_price', 10):.2f}",
        f"   â€¢ æœ€ä½å¹³å‡å‡ºæ¥é«˜: {format_large_number(params.get('min_avg_volume', 100000))}",
        f"   â€¢ æœ€ä½ä¾¡æ ¼å¤‰å‹•: {params.get('min_price_change', 2.0):.1f}%",
        f"   â€¢ ã‚½ãƒ¼ãƒˆ: {params.get('sort_by', 'price_change')} ({params.get('sort_order', 'desc')})",
        "",
        "=" * 100,
        ""
    ]
    
    # è©³ç´°ãªéŠ˜æŸ„ä¸€è¦§
    output_lines.extend([
        "ğŸ“ˆ è©³ç´°ãƒ‡ãƒ¼ã‚¿:",
        "",
        "| Ticker | Company | Sector | Price | Change | PreMkt | EPS Surprise | Revenue Surprise | Perf 1W | Volume |",
        "|--------|---------|--------|-------|--------|--------|--------------|------------------|---------|--------|"
    ])
    
    for i, stock in enumerate(results[:10]):  # ä¸Šä½10éŠ˜æŸ„
        price_str = f"${stock.price:.2f}" if stock.price else "N/A"
        change_str = f"{stock.price_change:.2f}%" if stock.price_change else "N/A"
        premarket_str = f"{stock.premarket_change_percent:.2f}%" if stock.premarket_change_percent else "N/A"
        eps_surprise_str = f"{stock.eps_surprise:.2f}%" if stock.eps_surprise else "N/A"
        revenue_surprise_str = f"{stock.revenue_surprise:.2f}%" if stock.revenue_surprise else "N/A"
        perf_1w_str = f"{stock.performance_1w:.2f}%" if stock.performance_1w else "N/A"
        volume_str = format_large_number(stock.volume) if stock.volume else "N/A"
        
        ticker_display = stock.ticker or "N/A"
        company_display = (stock.company_name[:15] + "...") if stock.company_name and len(stock.company_name) > 15 else (stock.company_name or "N/A")
        sector_display = (stock.sector[:12] + "...") if stock.sector and len(stock.sector) > 12 else (stock.sector or "N/A")
        
        output_lines.append(f"| {ticker_display:<6} | {company_display:<15} | {sector_display:<12} | {price_str:<7} | {change_str:<8} | {premarket_str:<8} | {eps_surprise_str:<12} | {revenue_surprise_str:<16} | {perf_1w_str:<7} | {volume_str:<6} |")
    
    output_lines.extend([
        "",
        "=" * 100,
        "",
        "ğŸ† ä¸Šä½5éŠ˜æŸ„ã®è©³ç´°åˆ†æ:",
        ""
    ])
    
    # ä¸Šä½5éŠ˜æŸ„ã®è©³ç´°æƒ…å ±
    for i, stock in enumerate(results[:5], 1):
        output_lines.extend([
            f"#{i} ğŸ“Š {stock.ticker} - {stock.company_name}",
            f"   ğŸ“ˆ Price: ${stock.price:.2f} | Change: {stock.price_change:.2f}%" if stock.price and stock.price_change else f"   ğŸ“ˆ Price: {stock.price:.2f} | Change: N/A" if stock.price else "   ğŸ“ˆ Price: N/A | Change: N/A",
            f"   ğŸ”” Premarket: {stock.premarket_change_percent:.2f}%" if stock.premarket_change_percent else "   ğŸ”” Premarket: N/A",
            f"   ğŸ’¼ Sector: {stock.sector} | Volume: {format_large_number(stock.volume)}" if stock.sector and stock.volume else f"   ğŸ’¼ Sector: {stock.sector or 'N/A'} | Volume: {format_large_number(stock.volume) if stock.volume else 'N/A'}",
            f"   ğŸ“Š EPS Surprise: {stock.eps_surprise:.2f}%" if stock.eps_surprise else "   ğŸ“Š EPS Surprise: N/A",
            f"   ğŸ’° Revenue Surprise: {stock.revenue_surprise:.2f}%" if stock.revenue_surprise else "   ğŸ’° Revenue Surprise: N/A",
            f"   ğŸ“ˆ Performance 1W: {stock.performance_1w:.2f}%" if stock.performance_1w else "   ğŸ“ˆ Performance 1W: N/A",
            ""
        ])
    
    # çµ±è¨ˆæƒ…å ±
    eps_surprises = [s.eps_surprise for s in results if s.eps_surprise is not None]
    revenue_surprises = [s.revenue_surprise for s in results if s.revenue_surprise is not None]
    
    if eps_surprises:
        avg_eps = sum(eps_surprises) / len(eps_surprises)
        max_eps = max(eps_surprises)
        output_lines.extend([
            "ğŸ“Š EPSã‚µãƒ—ãƒ©ã‚¤ã‚ºçµ±è¨ˆ:",
            f"   â€¢ å¹³å‡: {avg_eps:.2f}%",
            f"   â€¢ æœ€å¤§: {max_eps:.2f}%",
            f"   â€¢ ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(eps_surprises)}",
            ""
        ])
    
    # ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥åˆ†æ
    sector_counts = {}
    for stock in results:
        if stock.sector:
            sector_counts[stock.sector] = sector_counts.get(stock.sector, 0) + 1
    
    if sector_counts:
        output_lines.extend([
            "ğŸ¢ ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥åˆ†æ:",
            *[f"   â€¢ {sector}: {count}éŠ˜æŸ„" for sector, count in sorted(sector_counts.items(), key=lambda x: x[1], reverse=True)[:5]],
            ""
        ])
    
    return output_lines

def _format_earnings_afterhours_list(results: List, params: Dict[str, Any]) -> List[str]:
    """æ™‚é–“å¤–æ±ºç®—ä¸Šæ˜‡éŠ˜æŸ„ã®è©³ç´°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    def format_large_number(num):
        if not num:
            return "N/A"
        if num >= 1_000_000_000:
            return f"{num/1_000_000_000:.1f}B"
        elif num >= 1_000_000:
            return f"{num/1_000_000:.1f}M"
        elif num >= 1_000:
            return f"{num/1_000:.1f}K"
        else:
            return f"{num:.0f}"
    
    output_lines = [
        "ğŸŒ™ æ™‚é–“å¤–æ±ºç®—ä¸Šæ˜‡éŠ˜æŸ„ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœ",
        f"ğŸ“Š æ¤œå‡ºéŠ˜æŸ„æ•°: {len(results)}",
        "=" * 100,
        "",
        "ğŸ“‹ é©ç”¨ã•ã‚ŒãŸã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶:",
        f"   â€¢ æ™‚ä¾¡ç·é¡: {params.get('market_cap', 'smallover')} (ã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Š)",
        f"   â€¢ æ±ºç®—ã‚¿ã‚¤ãƒŸãƒ³ã‚°: {params.get('earnings_timing', 'today_after')} (ä»Šæ—¥ã®å¼•ã‘å¾Œ)",
        f"   â€¢ æœ€ä½ä¾¡æ ¼: ${params.get('min_price', 10):.2f}",
        f"   â€¢ æœ€ä½å¹³å‡å‡ºæ¥é«˜: {format_large_number(params.get('min_avg_volume', 100000))}",
        f"   â€¢ æœ€ä½æ™‚é–“å¤–å¤‰å‹•: {params.get('min_afterhours_change', 2.0):.1f}%",
        f"   â€¢ ã‚½ãƒ¼ãƒˆ: {params.get('sort_by', 'afterhours_change')} ({params.get('sort_order', 'desc')})",
        "",
        "=" * 100,
        ""
    ]
    
    # è©³ç´°ãªéŠ˜æŸ„ä¸€è¦§
    output_lines.extend([
        "ğŸ“ˆ è©³ç´°ãƒ‡ãƒ¼ã‚¿:",
        "",
        "| Ticker | Company | Sector | Price | Change | AftHrs | EPS Surprise | Revenue Surprise | Perf 1W | Volume |",
        "|--------|---------|--------|-------|--------|--------|--------------|------------------|---------|--------|"
    ])
    
    for i, stock in enumerate(results[:10]):  # ä¸Šä½10éŠ˜æŸ„
        price_str = f"${stock.price:.2f}" if stock.price else "N/A"
        change_str = f"{stock.price_change:.2f}%" if stock.price_change else "N/A"
        afterhours_str = f"{stock.afterhours_change_percent:.2f}%" if stock.afterhours_change_percent else "N/A"
        eps_surprise_str = f"{stock.eps_surprise:.2f}%" if stock.eps_surprise else "N/A"
        revenue_surprise_str = f"{stock.revenue_surprise:.2f}%" if stock.revenue_surprise else "N/A"
        perf_1w_str = f"{stock.performance_1w:.2f}%" if stock.performance_1w else "N/A"
        volume_str = format_large_number(stock.volume) if stock.volume else "N/A"
        
        ticker_display = stock.ticker or "N/A"
        company_display = (stock.company_name[:15] + "...") if stock.company_name and len(stock.company_name) > 15 else (stock.company_name or "N/A")
        sector_display = (stock.sector[:12] + "...") if stock.sector and len(stock.sector) > 12 else (stock.sector or "N/A")
        
        output_lines.append(f"| {ticker_display:<6} | {company_display:<15} | {sector_display:<12} | {price_str:<7} | {change_str:<8} | {afterhours_str:<8} | {eps_surprise_str:<12} | {revenue_surprise_str:<16} | {perf_1w_str:<7} | {volume_str:<6} |")
    
    output_lines.extend([
        "",
        "=" * 100,
        "",
        "ğŸ† ä¸Šä½5éŠ˜æŸ„ã®è©³ç´°åˆ†æ:",
        ""
    ])
    
    # ä¸Šä½5éŠ˜æŸ„ã®è©³ç´°æƒ…å ±
    for i, stock in enumerate(results[:5], 1):
        output_lines.extend([
            f"#{i} ğŸ“Š {stock.ticker} - {stock.company_name}",
            f"   ğŸ“ˆ Price: ${stock.price:.2f} | Change: {stock.price_change:.2f}%" if stock.price and stock.price_change else f"   ğŸ“ˆ Price: {stock.price:.2f} | Change: N/A" if stock.price else "   ğŸ“ˆ Price: N/A | Change: N/A",
            f"   ğŸŒ™ After Hours: {stock.afterhours_change_percent:.2f}%" if stock.afterhours_change_percent else "   ğŸŒ™ After Hours: N/A",
            f"   ğŸ’¼ Sector: {stock.sector} | Volume: {format_large_number(stock.volume)}" if stock.sector and stock.volume else f"   ğŸ’¼ Sector: {stock.sector or 'N/A'} | Volume: {format_large_number(stock.volume) if stock.volume else 'N/A'}",
            f"   ğŸ“Š EPS Surprise: {stock.eps_surprise:.2f}%" if stock.eps_surprise else "   ğŸ“Š EPS Surprise: N/A",
            f"   ğŸ’° Revenue Surprise: {stock.revenue_surprise:.2f}%" if stock.revenue_surprise else "   ğŸ’° Revenue Surprise: N/A",
            f"   ğŸ“ˆ Performance 1W: {stock.performance_1w:.2f}%" if stock.performance_1w else "   ğŸ“ˆ Performance 1W: N/A",
            ""
        ])
    
    # çµ±è¨ˆæƒ…å ±
    eps_surprises = [s.eps_surprise for s in results if s.eps_surprise is not None]
    revenue_surprises = [s.revenue_surprise for s in results if s.revenue_surprise is not None]
    
    if eps_surprises:
        avg_eps = sum(eps_surprises) / len(eps_surprises)
        max_eps = max(eps_surprises)
        output_lines.extend([
            "ğŸ“Š EPSã‚µãƒ—ãƒ©ã‚¤ã‚ºçµ±è¨ˆ:",
            f"   â€¢ å¹³å‡: {avg_eps:.2f}%",
            f"   â€¢ æœ€å¤§: {max_eps:.2f}%",
            f"   â€¢ ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(eps_surprises)}",
            ""
        ])
    
    # ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥åˆ†æ
    sector_counts = {}
    for stock in results:
        if stock.sector:
            sector_counts[stock.sector] = sector_counts.get(stock.sector, 0) + 1
    
    if sector_counts:
        output_lines.extend([
            "ğŸ¢ ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥åˆ†æ:",
            *[f"   â€¢ {sector}: {count}éŠ˜æŸ„" for sector, count in sorted(sector_counts.items(), key=lambda x: x[1], reverse=True)[:5]],
            ""
        ])
    
    return output_lines

def _format_earnings_trading_list(results: List, params: Dict[str, Any]) -> List[str]:
    """æ±ºç®—ãƒˆãƒ¬ãƒ¼ãƒ‰å¯¾è±¡éŠ˜æŸ„ã®è©³ç´°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    def format_large_number(num):
        if not num:
            return "N/A"
        if num >= 1_000_000_000:
            return f"{num/1_000_000_000:.1f}B"
        elif num >= 1_000_000:
            return f"{num/1_000_000:.1f}M"
        elif num >= 1_000:
            return f"{num/1_000:.1f}K"
        else:
            return f"{num:.0f}"
    
    output_lines = [
        "ğŸ¯ æ±ºç®—ãƒˆãƒ¬ãƒ¼ãƒ‰å¯¾è±¡éŠ˜æŸ„ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœ",
        f"ğŸ“Š æ¤œå‡ºéŠ˜æŸ„æ•°: {len(results)}",
        "=" * 100,
        "",
        "ğŸ“‹ é©ç”¨ã•ã‚ŒãŸã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶:",
        f"   â€¢ æ™‚ä¾¡ç·é¡: {params.get('market_cap', 'smallover')} (ã‚¹ãƒ¢ãƒ¼ãƒ«ä»¥ä¸Š)",
        f"   â€¢ æ±ºç®—æœŸé–“: {params.get('earnings_window', 'yesterday_after_today_before')} (æ˜¨æ—¥å¼•ã‘å¾Œ-ä»Šæ—¥å¯„ã‚Šä»˜ãå‰)",
        f"   â€¢ æœ€ä½ä¾¡æ ¼: ${params.get('min_price', 10):.2f}",
        f"   â€¢ æœ€ä½å¹³å‡å‡ºæ¥é«˜: {format_large_number(params.get('min_avg_volume', 200000))}",
        f"   â€¢ æ±ºç®—äºˆæƒ³ä¿®æ­£: {params.get('earnings_revision', 'eps_revenue_positive')} (EPS/å£²ä¸Šä¸Šæ–¹ä¿®æ­£)",
        f"   â€¢ ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰: {params.get('price_trend', 'positive_change')} (ãƒã‚¸ãƒ†ã‚£ãƒ–)",
        f"   â€¢ 4é€±ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: {params.get('performance_4w_range', '0_to_negative_4w')} (å›å¾©å€™è£œ)",
        f"   â€¢ æœ€ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {params.get('min_volatility', 1.0):.1f}å€",
        f"   â€¢ ã‚½ãƒ¼ãƒˆ: {params.get('sort_by', 'eps_surprise')} ({params.get('sort_order', 'desc')})",
        "",
        "=" * 100,
        ""
    ]
    
    # è©³ç´°ãªéŠ˜æŸ„ä¸€è¦§
    output_lines.extend([
        "ğŸ“ˆ è©³ç´°ãƒ‡ãƒ¼ã‚¿:",
        "",
        "| Ticker | Company | Sector | Price | Change | EPS Surprise | Revenue Surprise | Perf 1W | Volatility | Volume |",
        "|--------|---------|--------|-------|--------|--------------|------------------|---------|------------|--------|"
    ])
    
    for i, stock in enumerate(results[:10]):  # ä¸Šä½10éŠ˜æŸ„
        price_str = f"${stock.price:.2f}" if stock.price else "N/A"
        change_str = f"{stock.price_change:.2f}%" if stock.price_change else "N/A"
        eps_surprise_str = f"{stock.eps_surprise:.2f}%" if stock.eps_surprise else "N/A"
        revenue_surprise_str = f"{stock.revenue_surprise:.2f}%" if stock.revenue_surprise else "N/A"
        perf_1w_str = f"{stock.performance_1w:.2f}%" if stock.performance_1w else "N/A"
        volatility_str = f"{stock.volatility:.2f}" if stock.volatility else "N/A"
        volume_str = format_large_number(stock.volume) if stock.volume else "N/A"
        
        ticker_display = stock.ticker or "N/A"
        company_display = (stock.company_name[:15] + "...") if stock.company_name and len(stock.company_name) > 15 else (stock.company_name or "N/A")
        sector_display = (stock.sector[:12] + "...") if stock.sector and len(stock.sector) > 12 else (stock.sector or "N/A")
        
        output_lines.append(f"| {ticker_display:<6} | {company_display:<15} | {sector_display:<12} | {price_str:<7} | {change_str:<8} | {eps_surprise_str:<12} | {revenue_surprise_str:<16} | {perf_1w_str:<7} | {volatility_str:<10} | {volume_str:<6} |")
    
    output_lines.extend([
        "",
        "=" * 100,
        "",
        "ğŸ† ä¸Šä½5éŠ˜æŸ„ã®è©³ç´°åˆ†æ:",
        ""
    ])
    
    # ä¸Šä½5éŠ˜æŸ„ã®è©³ç´°æƒ…å ±
    for i, stock in enumerate(results[:5], 1):
        output_lines.extend([
            f"#{i} ğŸ“Š {stock.ticker} - {stock.company_name}",
            f"   ğŸ“ˆ Price: ${stock.price:.2f} | Change: {stock.price_change:.2f}%" if stock.price and stock.price_change else f"   ğŸ“ˆ Price: {stock.price:.2f} | Change: N/A" if stock.price else "   ğŸ“ˆ Price: N/A | Change: N/A",
            f"   ğŸ’¼ Sector: {stock.sector} | Volume: {format_large_number(stock.volume)}" if stock.sector and stock.volume else f"   ğŸ’¼ Sector: {stock.sector or 'N/A'} | Volume: {format_large_number(stock.volume) if stock.volume else 'N/A'}",
            f"   ğŸ“Š EPS Surprise: {stock.eps_surprise:.2f}%" if stock.eps_surprise else "   ğŸ“Š EPS Surprise: N/A",
            f"   ğŸ’° Revenue Surprise: {stock.revenue_surprise:.2f}%" if stock.revenue_surprise else "   ğŸ’° Revenue Surprise: N/A",
            f"   ğŸ“ˆ Performance 1W: {stock.performance_1w:.2f}%" if stock.performance_1w else "   ğŸ“ˆ Performance 1W: N/A",
            f"   ğŸ“Š Volatility: {stock.volatility:.2f}" if stock.volatility else "   ğŸ“Š Volatility: N/A",
            f"   ğŸ“ˆ Performance 1M: {stock.performance_1m:.2f}%" if stock.performance_1m else "   ğŸ“ˆ Performance 1M: N/A",
            ""
        ])
    
    # çµ±è¨ˆæƒ…å ±
    eps_surprises = [s.eps_surprise for s in results if s.eps_surprise is not None]
    revenue_surprises = [s.revenue_surprise for s in results if s.revenue_surprise is not None]
    volatilities = [s.volatility for s in results if s.volatility is not None]
    
    if eps_surprises:
        avg_eps = sum(eps_surprises) / len(eps_surprises)
        max_eps = max(eps_surprises)
        output_lines.extend([
            "ğŸ“Š EPSã‚µãƒ—ãƒ©ã‚¤ã‚ºçµ±è¨ˆ:",
            f"   â€¢ å¹³å‡: {avg_eps:.2f}%",
            f"   â€¢ æœ€å¤§: {max_eps:.2f}%",
            f"   â€¢ ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(eps_surprises)}",
            ""
        ])
    
    if volatilities:
        avg_volatility = sum(volatilities) / len(volatilities)
        max_volatility = max(volatilities)
        output_lines.extend([
            "ğŸ“Š ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çµ±è¨ˆ:",
            f"   â€¢ å¹³å‡: {avg_volatility:.2f}",
            f"   â€¢ æœ€å¤§: {max_volatility:.2f}",
            f"   â€¢ ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(volatilities)}",
            ""
        ])
    
    # ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥åˆ†æ
    sector_counts = {}
    for stock in results:
        if stock.sector:
            sector_counts[stock.sector] = sector_counts.get(stock.sector, 0) + 1
    
    if sector_counts:
        output_lines.extend([
            "ğŸ¢ ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥åˆ†æ:",
            *[f"   â€¢ {sector}: {count}éŠ˜æŸ„" for sector, count in sorted(sector_counts.items(), key=lambda x: x[1], reverse=True)[:5]],
            ""
        ])
    
    return output_lines

@server.tool()
def get_sec_filings(
    ticker: str,
    form_types: Optional[List[str]] = None,
    days_back: int = 30,
    max_results: int = 50,
    sort_by: str = "filing_date",
    sort_order: str = "desc"
) -> List[TextContent]:
    """
    æŒ‡å®šéŠ˜æŸ„ã®SECãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Args:
        ticker: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼
        form_types: ãƒ•ã‚©ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ (ä¾‹: ["10-K", "10-Q", "8-K"])
        days_back: éå»ä½•æ—¥åˆ†ã®ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30æ—¥)
        max_results: æœ€å¤§å–å¾—ä»¶æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ä»¶)
        sort_by: ã‚½ãƒ¼ãƒˆåŸºæº– ("filing_date", "report_date", "form")
        sort_order: ã‚½ãƒ¼ãƒˆé †åº ("asc", "desc")
    """
    try:
        # Validate ticker
        if not validate_ticker(ticker):
            raise ValueError(f"Invalid ticker: {ticker}")
        
        # Get SEC filings data
        filings = finviz_sec.get_sec_filings(
            ticker=ticker,
            form_types=form_types,
            days_back=days_back,
            max_results=max_results,
            sort_by=sort_by,
            sort_order=sort_order
        )
        
        if not filings:
            return [TextContent(type="text", text=f"No SEC filings found for {ticker} in the last {days_back} days.")]
        
        # Format output
        form_filter_text = f" (Forms: {', '.join(form_types)})" if form_types else ""
        output_lines = [
            f"ğŸ“„ SEC Filings for {ticker}{form_filter_text}:",
            f"ğŸ“… Period: Last {days_back} days | Results: {len(filings)} filings",
            "=" * 80,
            ""
        ]
        
        for filing in filings:
            output_lines.extend([
                f"ğŸ“… Filing Date: {filing.filing_date} | Report Date: {filing.report_date}",
                f"ğŸ“‹ Form: {filing.form}",
                f"ğŸ“ Description: {filing.description}",
                f"ğŸ”— Filing URL: {filing.filing_url}",
                f"ğŸ“„ Document URL: {filing.document_url}",
                "-" * 60,
                ""
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_sec_filings: {str(e)}")
        raise e
    except Exception as e:
        logger.error(f"Error in get_sec_filings: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_major_sec_filings(
    ticker: str,
    days_back: int = 90
) -> List[TextContent]:
    """
    ä¸»è¦ãªSECãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ï¼ˆ10-K, 10-Q, 8-Kç­‰ï¼‰ã‚’å–å¾—
    
    Args:
        ticker: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼
        days_back: éå»ä½•æ—¥åˆ†ã®ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 90æ—¥)
    """
    try:
        # Validate ticker
        if not validate_ticker(ticker):
            raise ValueError(f"Invalid ticker: {ticker}")
        
        # Get major filings
        filings = finviz_sec.get_major_filings(ticker, days_back)
        
        if not filings:
            return [TextContent(type="text", text=f"No major SEC filings found for {ticker} in the last {days_back} days.")]
        
        # Format output
        output_lines = [
            f"ğŸ“Š Major SEC Filings for {ticker}:",
            f"ğŸ“… Period: Last {days_back} days | Results: {len(filings)} filings",
            "=" * 80,
            "",
            "ğŸ“‹ Form Types: 10-K (Annual), 10-Q (Quarterly), 8-K (Current), DEF 14A (Proxy), SC 13G/D (Ownership)",
            "",
            "=" * 80,
            ""
        ]
        
        # Group by form type for better organization
        forms_dict = {}
        for filing in filings:
            form_type = filing.form
            if form_type not in forms_dict:
                forms_dict[form_type] = []
            forms_dict[form_type].append(filing)
        
        for form_type, form_filings in forms_dict.items():
            output_lines.extend([
                f"ğŸ“‹ Form {form_type} ({len(form_filings)} filings):",
                "-" * 40,
                ""
            ])
            
            for filing in form_filings:
                output_lines.extend([
                    f"  ğŸ“… {filing.filing_date} | Report: {filing.report_date}",
                    f"  ğŸ“ {filing.description}",
                    f"  ğŸ”— Filing: {filing.filing_url}",
                    f"  ğŸ“„ Document: {filing.document_url}",
                    ""
                ])
            
            output_lines.append("")
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_major_sec_filings: {str(e)}")
        raise e
    except Exception as e:
        logger.error(f"Error in get_major_sec_filings: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_insider_sec_filings(
    ticker: str,
    days_back: int = 30
) -> List[TextContent]:
    """
    ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼å–å¼•é–¢é€£ã®SECãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ï¼ˆãƒ•ã‚©ãƒ¼ãƒ 3, 4, 5ç­‰ï¼‰ã‚’å–å¾—
    
    Args:
        ticker: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼
        days_back: éå»ä½•æ—¥åˆ†ã®ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30æ—¥)
    """
    try:
        # Validate ticker
        if not validate_ticker(ticker):
            raise ValueError(f"Invalid ticker: {ticker}")
        
        # Get insider filings
        filings = finviz_sec.get_insider_filings(ticker, days_back)
        
        if not filings:
            return [TextContent(type="text", text=f"No insider SEC filings found for {ticker} in the last {days_back} days.")]
        
        # Format output
        output_lines = [
            f"ğŸ‘¥ Insider SEC Filings for {ticker}:",
            f"ğŸ“… Period: Last {days_back} days | Results: {len(filings)} filings",
            "=" * 80,
            "",
            "ğŸ“‹ Form Types:",
            "  â€¢ Form 3: Initial ownership statement",
            "  â€¢ Form 4: Statement of changes in beneficial ownership",
            "  â€¢ Form 5: Annual statement of changes in beneficial ownership",
            "  â€¢ 11-K: Annual reports of employee stock purchase plans",
            "",
            "=" * 80,
            ""
        ]
        
        for filing in filings:
            # Determine filing type explanation
            form_explanation = {
                "3": "Initial ownership statement",
                "4": "Changes in beneficial ownership",
                "5": "Annual ownership changes",
                "11-K": "Employee stock purchase plan report"
            }.get(filing.form, "Insider-related filing")
            
            output_lines.extend([
                f"ğŸ“‹ Form {filing.form} - {form_explanation}",
                f"ğŸ“… Filing: {filing.filing_date} | Report: {filing.report_date}",
                f"ğŸ“ {filing.description}",
                f"ğŸ”— Filing: {filing.filing_url}",
                f"ğŸ“„ Document: {filing.document_url}",
                "-" * 60,
                ""
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_insider_sec_filings: {str(e)}")
        raise e
    except Exception as e:
        logger.error(f"Error in get_insider_sec_filings: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_sec_filing_summary(
    ticker: str,
    days_back: int = 90
) -> List[TextContent]:
    """
    æŒ‡å®šæœŸé–“ã®SECãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ¦‚è¦ã¨ã‚µãƒãƒªãƒ¼ã‚’å–å¾—
    
    Args:
        ticker: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼
        days_back: éå»ä½•æ—¥åˆ†ã®æ¦‚è¦ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 90æ—¥)
    """
    try:
        # Validate ticker
        if not validate_ticker(ticker):
            raise ValueError(f"Invalid ticker: {ticker}")
        
        # Get filing summary
        summary = finviz_sec.get_filing_summary(ticker, days_back)
        
        if "error" in summary:
            return [TextContent(type="text", text=f"Error getting filing summary for {ticker}: {summary['error']}")]
        
        if summary.get("total_filings", 0) == 0:
            return [TextContent(type="text", text=f"No SEC filings found for {ticker} in the last {days_back} days.")]
        
        # Format output
        output_lines = [
            f"ğŸ“Š SEC Filing Summary for {ticker}:",
            f"ğŸ“… Period: Last {summary['period_days']} days",
            f"ğŸ“„ Total Filings: {summary['total_filings']}",
            f"ğŸ“… Latest Filing: {summary.get('latest_filing_date', 'N/A')} ({summary.get('latest_filing_form', 'N/A')})",
            "=" * 60,
            "",
            "ğŸ“‹ Filing Breakdown by Form Type:",
            "-" * 40
        ]
        
        # Sort forms by count (descending)
        forms = summary.get("forms", {})
        sorted_forms = sorted(forms.items(), key=lambda x: x[1], reverse=True)
        
        for form_type, count in sorted_forms:
            percentage = (count / summary['total_filings'] * 100) if summary['total_filings'] > 0 else 0
            output_lines.append(f"  ğŸ“‹ {form_type}: {count} filings ({percentage:.1f}%)")
        
        output_lines.extend([
            "",
            "ğŸ“ Common Form Types:",
            "  â€¢ 10-K: Annual report (comprehensive overview)",
            "  â€¢ 10-Q: Quarterly report (financial updates)",
            "  â€¢ 8-K: Current report (material events)",
            "  â€¢ DEF 14A: Proxy statement (shareholder meetings)",
            "  â€¢ 4: Insider trading activities",
            "  â€¢ SC 13G/D: Beneficial ownership (>5% ownership changes)"
        ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_sec_filing_summary: {str(e)}")
        raise e
    except Exception as e:
        logger.error(f"Error in get_sec_filing_summary: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_edgar_filing_content(
    ticker: str,
    accession_number: str,
    primary_document: str,
    max_length: int = 50000
) -> List[TextContent]:
    """
    EDGAR APIçµŒç”±ã§SECãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ã‚’å–å¾—
    
    Args:
        ticker: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼
        accession_number: SEC accession number (with dashes)
        primary_document: Primary document filename
        max_length: æœ€å¤§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é•· (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50,000æ–‡å­—)
    """
    try:
        # Validate ticker
        if not validate_ticker(ticker):
            raise ValueError(f"Invalid ticker: {ticker}")
        
        logger.info(f"Fetching EDGAR document content for {ticker}: {accession_number}/{primary_document}")
        
        # Get document content via EDGAR API
        content_data = edgar_client.get_filing_document_content(
            ticker=ticker,
            accession_number=accession_number,
            primary_document=primary_document,
            max_length=max_length
        )
        
        if content_data.get('status') == 'error':
            return [TextContent(type="text", text=f"Error: {content_data.get('error', 'Unknown error')}")]
        
        # Format output
        metadata = content_data.get('metadata', {})
        content = content_data.get('content', '')
        
        output_lines = [
            f"ğŸ“„ SEC Filing Document Content for {ticker}:",
            f"ğŸ”— Document: {accession_number}/{primary_document}",
            f"ğŸ“… Retrieved: {metadata.get('retrieved_at', 'N/A')}",
            f"ğŸ“Š Content Length: {metadata.get('content_length', 0):,} characters",
            "=" * 80,
            "",
            content[:max_length] if len(content) > max_length else content
        ]
        
        if len(content) > max_length:
            output_lines.extend([
                "",
                "=" * 80,
                f"[Content truncated - showing first {max_length:,} characters]"
            ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_edgar_filing_content: {str(e)}")
        raise e
    except Exception as e:
        logger.error(f"Error in get_edgar_filing_content: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_multiple_edgar_filing_contents(
    ticker: str,
    filings_data: List[Dict[str, str]],
    max_length: int = 20000
) -> List[TextContent]:
    """
    è¤‡æ•°ã®SECãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ã‚’EDGAR APIçµŒç”±ã§ä¸€æ‹¬å–å¾—
    
    Args:
        ticker: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼
        filings_data: ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ [{"accession_number": "...", "primary_document": "..."}]
        max_length: å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æœ€å¤§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é•· (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20,000æ–‡å­—)
    """
    try:
        # Validate ticker
        if not validate_ticker(ticker):
            raise ValueError(f"Invalid ticker: {ticker}")
        
        if not filings_data:
            return [TextContent(type="text", text="No filing data provided.")]
        
        logger.info(f"Fetching {len(filings_data)} EDGAR document contents for {ticker}")
        
        # Prepare filing data with ticker
        filings_with_ticker = []
        for filing in filings_data:
            filing_copy = filing.copy()
            filing_copy['ticker'] = ticker
            filings_with_ticker.append(filing_copy)
        
        # Get multiple document contents via EDGAR API
        results = edgar_client.get_multiple_filing_contents(
            filings_data=filings_with_ticker,
            max_length=max_length
        )
        
        if not results:
            return [TextContent(type="text", text=f"No document contents retrieved for {ticker}.")]
        
        # Format output
        output_lines = [
            f"ğŸ“„ Multiple SEC Filing Document Contents for {ticker}:",
            f"ğŸ“Š Retrieved: {len(results)} documents",
            "=" * 80,
            ""
        ]
        
        for i, result in enumerate(results, 1):
            metadata = result.get('metadata', {})
            content = result.get('content', '')
            status = result.get('status', 'unknown')
            
            output_lines.extend([
                f"ğŸ“‹ Document {i}/{len(results)}:",
                f"   ğŸ“„ File: {metadata.get('accession_number', 'N/A')}/{metadata.get('primary_document', 'N/A')}",
                f"   ğŸ“… Retrieved: {metadata.get('retrieved_at', 'N/A')}",
                f"   ğŸ“Š Length: {metadata.get('content_length', 0):,} characters",
                f"   âœ… Status: {status}",
                ""
            ])
            
            if status == 'error':
                error_msg = result.get('error', 'Unknown error')
                output_lines.extend([
                    f"   âŒ Error: {error_msg}",
                    ""
                ])
            else:
                # Show first 500 characters of content
                preview_length = min(500, len(content))
                preview = content[:preview_length]
                output_lines.extend([
                    f"   ğŸ“ Content Preview ({preview_length} chars):",
                    f"   {preview}",
                    ""
                ])
                
                if len(content) > preview_length:
                    output_lines.append(f"   [... {len(content) - preview_length:,} more characters]")
                    output_lines.append("")
            
            output_lines.extend(["-" * 60, ""])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_multiple_edgar_filing_contents: {str(e)}")
        raise e
    except Exception as e:
        logger.error(f"Error in get_multiple_edgar_filing_contents: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_edgar_company_filings(
    ticker: str,
    form_types: Optional[List[str]] = None,
    max_count: int = 50,
    days_back: int = 365
) -> List[TextContent]:
    """
    EDGAR APIçµŒç”±ã§ä¼æ¥­ã®ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ä¸€è¦§ã‚’å–å¾—
    
    Args:
        ticker: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼
        form_types: ãƒ•ã‚©ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ (ä¾‹: ["10-K", "10-Q", "8-K"])
        max_count: æœ€å¤§å–å¾—ä»¶æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50)
        days_back: éå»ä½•æ—¥åˆ† (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 365æ—¥)
    """
    try:
        # Validate ticker
        if not validate_ticker(ticker):
            raise ValueError(f"Invalid ticker: {ticker}")
        
        logger.info(f"Fetching EDGAR filings for {ticker} via EDGAR API")
        
        # Calculate date range
        from datetime import datetime, timedelta
        date_to = datetime.now().strftime('%Y-%m-%d')
        date_from = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
        
        # Get company filings via EDGAR API
        filings = edgar_client.get_company_filings(
            ticker=ticker,
            form_types=form_types,
            date_from=date_from,
            date_to=date_to,
            max_count=max_count
        )
        
        if not filings:
            form_filter_text = f" (forms: {', '.join(form_types)})" if form_types else ""
            return [TextContent(type="text", text=f"No EDGAR filings found for {ticker}{form_filter_text} in the last {days_back} days.")]
        
        # Format output
        output_lines = [
            f"ğŸ“Š EDGAR Company Filings for {ticker}:",
            f"ğŸ“… Period: {date_from} to {date_to} ({days_back} days)",
            f"ğŸ“„ Results: {len(filings)} filings",
        ]
        
        if form_types:
            output_lines.append(f"ğŸ“‹ Form Filter: {', '.join(form_types)}")
        
        output_lines.extend([
            "=" * 80,
            "",
            "ğŸ“‹ Available Form Types:",
            "  â€¢ 10-K: Annual report",
            "  â€¢ 10-Q: Quarterly report", 
            "  â€¢ 8-K: Current report (material events)",
            "  â€¢ DEF 14A: Proxy statement",
            "  â€¢ 4: Statement of changes in beneficial ownership",
            "",
            "=" * 80,
            ""
        ])
        
        for filing in filings:
            output_lines.extend([
                f"ğŸ“‹ Form {filing['form']} - {filing.get('description', 'N/A')}",
                f"ğŸ“… Filing: {filing['filing_date']} | Report: {filing['report_date']}",
                f"ğŸ“„ Document: {filing['accession_number']}/{filing['primary_document']}",
                f"ğŸ”— Filing URL: {filing['filing_url']}",
                f"ğŸ“„ Document URL: {filing['document_url']}",
                "-" * 60,
                ""
            ])
        
        output_lines.extend([
            "",
            "ğŸ’¡ To get document content, use get_edgar_filing_content with:",
            "   ticker, accession_number, and primary_document from above"
        ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_edgar_company_filings: {str(e)}")
        raise e
    except Exception as e:
        logger.error(f"Error in get_edgar_company_filings: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_edgar_company_facts(
    ticker: str
) -> List[TextContent]:
    """
    EDGAR APIçµŒç”±ã§ä¼æ¥­ã®åŸºæœ¬æƒ…å ±ã¨ãƒ•ã‚¡ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Args:
        ticker: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼
    """
    try:
        # Validate ticker
        if not validate_ticker(ticker):
            raise ValueError(f"Invalid ticker: {ticker}")
        
        logger.info(f"Fetching EDGAR company facts for {ticker}")
        
        # Get CIK from ticker first
        cik = edgar_client._get_cik_from_ticker(ticker)
        if not cik:
            return [TextContent(type="text", text=f"Could not find CIK for ticker {ticker}. Please verify the ticker symbol.")]
        
        # Get company facts via EDGAR API
        try:
            company_facts = edgar_client.client.get_company_facts(cik)
        except Exception as e:
            return [TextContent(type="text", text=f"Error fetching company facts for {ticker}: {str(e)}")]
        
        if not company_facts:
            return [TextContent(type="text", text=f"No company facts found for {ticker}.")]
        
        # Extract basic information
        cik = company_facts.get('cik', 'N/A')
        entity_name = company_facts.get('entityName', 'N/A')
        
        # Format output
        output_lines = [
            f"ğŸ¢ EDGAR Company Facts for {ticker}:",
            f"ğŸ“Š Entity Name: {entity_name}",
            f"ğŸ”¢ CIK: {cik}",
            "=" * 60,
            ""
        ]
        
        # Show available facts/concepts
        facts = company_facts.get('facts', {})
        if facts:
            output_lines.extend([
                "ğŸ“‹ Available Financial Concepts:",
                ""
            ])
            
            # Group by taxonomy
            for taxonomy, concepts in facts.items():
                if concepts:
                    output_lines.extend([
                        f"ğŸ“Š {taxonomy.upper()} Taxonomy:",
                        f"   ğŸ“ˆ Available concepts: {len(concepts)}",
                        ""
                    ])
                    
                    # Show first few concepts as examples
                    concept_names = list(concepts.keys())[:5]
                    for concept in concept_names:
                        concept_data = concepts[concept]
                        description = concept_data.get('description', concept)
                        output_lines.append(f"   â€¢ {concept}: {description}")
                    
                    if len(concepts) > 5:
                        output_lines.append(f"   ... and {len(concepts) - 5} more concepts")
                    
                    output_lines.append("")
        
        output_lines.extend([
            "ğŸ’¡ To get specific concept data, use get_edgar_company_concept with:",
            f"   ticker='{ticker}', concept='Assets', taxonomy='us-gaap'"
        ])
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_edgar_company_facts: {str(e)}")
        raise e
    except Exception as e:
        logger.error(f"Error in get_edgar_company_facts: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]

@server.tool()
def get_edgar_company_concept(
    ticker: str,
    concept: str,
    taxonomy: str = "us-gaap"
) -> List[TextContent]:
    """
    EDGAR APIçµŒç”±ã§ä¼æ¥­ã®ç‰¹å®šã®è²¡å‹™ã‚³ãƒ³ã‚»ãƒ—ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Args:
        ticker: éŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼
        concept: XBRLã‚³ãƒ³ã‚»ãƒ—ãƒˆ (ä¾‹: 'Assets', 'Revenues', 'NetIncomeLoss')
        taxonomy: ã‚¿ã‚¯ã‚½ãƒãƒŸãƒ¼ ('us-gaap', 'dei', 'invest')
    """
    try:
        # Validate ticker
        if not validate_ticker(ticker):
            raise ValueError(f"Invalid ticker: {ticker}")
        
        logger.info(f"Fetching EDGAR concept {concept} for {ticker}")
        
        # Get company concept via EDGAR API
        concept_data = edgar_client.get_company_concept(
            ticker=ticker,
            concept=concept,
            taxonomy=taxonomy
        )
        
        if 'error' in concept_data:
            return [TextContent(type="text", text=f"Error: {concept_data['error']}")]
        
        # Extract basic information
        cik = concept_data.get('cik', 'N/A')
        entity_name = concept_data.get('entityName', 'N/A')
        concept_label = concept_data.get('label', concept)
        description = concept_data.get('description', 'N/A')
        
        # Format output
        output_lines = [
            f"ğŸ“Š EDGAR Company Concept: {ticker} - {concept}",
            f"ğŸ¢ Entity: {entity_name} (CIK: {cik})",
            f"ğŸ“‹ Concept: {concept_label}",
            f"ğŸ“ Description: {description}",
            f"ğŸ·ï¸ Taxonomy: {taxonomy}",
            "=" * 80,
            ""
        ]
        
        # Show units and values
        units = concept_data.get('units', {})
        if units:
            output_lines.append("ğŸ“Š Available Data Units:")
            output_lines.append("")
            
            for unit_type, unit_data in units.items():
                output_lines.extend([
                    f"ğŸ’° Unit: {unit_type}",
                    f"   ğŸ“ˆ Data points: {len(unit_data)}",
                    ""
                ])
                
                # Show recent values
                if unit_data:
                    output_lines.append("   ğŸ“… Recent Values:")
                    # Sort by end date (most recent first)
                    sorted_data = sorted(unit_data, key=lambda x: x.get('end', ''), reverse=True)
                    
                    for i, entry in enumerate(sorted_data[:10]):  # Show last 10 entries
                        end_date = entry.get('end', 'N/A')
                        value = entry.get('val', 'N/A')
                        form = entry.get('form', 'N/A')
                        filed = entry.get('filed', 'N/A')
                        
                        # Format large numbers
                        if isinstance(value, (int, float)):
                            if value >= 1_000_000_000:
                                formatted_value = f"${value/1_000_000_000:.2f}B"
                            elif value >= 1_000_000:
                                formatted_value = f"${value/1_000_000:.2f}M"
                            elif value >= 1_000:
                                formatted_value = f"${value/1_000:.2f}K"
                            else:
                                formatted_value = f"${value:,.2f}"
                        else:
                            formatted_value = str(value)
                        
                        output_lines.append(f"   â€¢ {end_date}: {formatted_value} ({form} filed: {filed})")
                    
                    if len(sorted_data) > 10:
                        output_lines.append(f"   ... and {len(sorted_data) - 10} more entries")
                
                output_lines.append("")
        else:
            output_lines.append("âš ï¸ No unit data available for this concept.")
        
        return [TextContent(type="text", text="\n".join(output_lines))]
        
    except (ValueError, TypeError) as e:
        logger.error(f"Validation error in get_edgar_company_concept: {str(e)}")
        raise e
    except Exception as e:
        logger.error(f"Error in get_edgar_company_concept: {str(e)}")
        return [TextContent(type="text", text=f"Error: {str(e)}")]
