#!/usr/bin/env python3
"""
Finviz HTML ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä¿å­˜ã•ã‚ŒãŸFinviz HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ã€
åˆ©ç”¨å¯èƒ½ãªå…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é …ç›®ã¨ãã®å€¤ã‚’è©³ç´°ã«è§£æã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

Usage:
    python finviz_html_analyzer.py [html_file_path]
"""

from bs4 import BeautifulSoup
import json
import re
from dataclasses import dataclass
from typing import List, Dict, Optional
import sys
import os
from pathlib import Path
import argparse
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class FilterOption:
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    value: str
    label: str
    group: Optional[str] = None

@dataclass
class FilterParameter:
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    name: str
    id: str
    data_filter: str
    options: List[FilterOption]
    selected_value: Optional[str] = None
    category: Optional[str] = None
    data_url: Optional[str] = None
    data_url_selected: Optional[str] = None

class FinvizHTMLAnalyzer:
    """Finviz HTMLè§£æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, html_file_path: str):
        self.html_file_path = Path(html_file_path)
        self.filters = []
        
        # é™¤å¤–ã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ãƒªã‚¹ãƒˆï¼ˆå€‹äººè¨­å®šç­‰ï¼‰
        self.excluded_filters = {
            'screenerpresetsselect',     # ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠ
            'screenerpresets',           # ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ãƒ—ãƒªã‚»ãƒƒãƒˆ
            'fs_screenerpresetsselect',  # ãƒ•ãƒ«IDãƒãƒ¼ã‚¸ãƒ§ãƒ³
            'fs_screenerpresets',        # ãƒ•ãƒ«IDãƒãƒ¼ã‚¸ãƒ§ãƒ³
        }
        
        if not self.html_file_path.exists():
            raise FileNotFoundError(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {html_file_path}")
        
        logger.info(f"é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: {', '.join(self.excluded_filters)}")
    
    def load_html(self) -> BeautifulSoup:
        """HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(self.html_file_path, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            soup = BeautifulSoup(html_content, 'html.parser')
            logger.info(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.html_file_path}")
            return soup
            
        except UnicodeDecodeError:
            # UTF-8ã§èª­ã¿è¾¼ã‚ãªã„å ´åˆã€ä»–ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
            try:
                with open(self.html_file_path, 'r', encoding='iso-8859-1') as f:
                    html_content = f.read()
                soup = BeautifulSoup(html_content, 'html.parser')
                logger.info(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ (iso-8859-1): {self.html_file_path}")
                return soup
            except Exception as e:
                logger.error(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                raise
        except Exception as e:
            logger.error(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def extract_filter_parameters(self) -> List[FilterParameter]:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’æŠ½å‡º"""
        try:
            soup = self.load_html()
            filters = []
            
            # selectã‚¿ã‚°ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¦ç´ ã‚’æ¤œç´¢ï¼ˆè¤‡æ•°ã®ã‚¯ãƒ©ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰
            select_patterns = [
                {'class': re.compile(r'screener-combo')},
                {'class': re.compile(r'fv-select')},
                {'class': re.compile(r'screener.*combo')},
                {'id': re.compile(r'^fs_')},  # IDãŒfs_ã§å§‹ã¾ã‚‹ã‚‚ã®
            ]
            
            found_selects = set()  # é‡è¤‡ã‚’é˜²ã
            
            for pattern in select_patterns:
                selects = soup.find_all('select', pattern)
                for select in selects:
                    select_id = select.get('id', '')
                    if select_id and select_id not in found_selects:
                        found_selects.add(select_id)
                        try:
                            filter_param = self._parse_select_element(select)
                            if filter_param:
                                filters.append(filter_param)
                        except Exception as e:
                            logger.warning(f"selectã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆè§£æã‚¨ãƒ©ãƒ¼ ({select_id}): {e}")
                            continue
            
            # data-filterå±æ€§ã‚’æŒã¤selectè¦ç´ ã‚‚æ¤œç´¢
            data_filter_selects = soup.find_all('select', attrs={'data-filter': True})
            for select in data_filter_selects:
                select_id = select.get('id', '')
                if select_id and select_id not in found_selects:
                    found_selects.add(select_id)
                    try:
                        filter_param = self._parse_select_element(select)
                        if filter_param:
                            filters.append(filter_param)
                    except Exception as e:
                        logger.warning(f"data-filter selectè§£æã‚¨ãƒ©ãƒ¼ ({select_id}): {e}")
                        continue
            
            logger.info(f"{len(filters)}å€‹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’data-filteré †ã§ã‚½ãƒ¼ãƒˆ
            filters.sort(key=lambda x: x.data_filter)
            
            return filters
            
        except Exception as e:
            logger.error(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _parse_select_element(self, select) -> Optional[FilterParameter]:
        """selectã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã‚’è§£æã—ã¦FilterParameterã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ"""
        try:
            # åŸºæœ¬å±æ€§ã‚’å–å¾—
            select_id = select.get('id', '')
            data_filter = select.get('data-filter', '')
            data_url = select.get('data-url', '')
            data_url_selected = select.get('data-url-selected', '')
            
            if not data_filter and not select_id:
                return None
            
            # data-filterãŒãªã„å ´åˆã€IDã‹ã‚‰æ¨æ¸¬
            if not data_filter and select_id.startswith('fs_'):
                data_filter = select_id[3:]  # fs_ã‚’é™¤å»
            
            # é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
            if (select_id.lower() in self.excluded_filters or 
                data_filter.lower() in self.excluded_filters):
                logger.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é™¤å¤–ã—ã¾ã—ãŸ: {select_id} (data-filter: {data_filter})")
                return None
            
            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è§£æ
            options = []
            current_group = None
            
            for element in select.find_all(['option', 'optgroup']):
                if element.name == 'optgroup':
                    current_group = element.get('label', '')
                elif element.name == 'option':
                    value = element.get('value', '')
                    label = element.get_text(strip=True)
                    
                    # ç©ºã®ãƒ©ãƒ™ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if not label:
                        continue
                    
                    option = FilterOption(
                        value=value,
                        label=label,
                        group=current_group
                    )
                    options.append(option)
            
            # é¸æŠã•ã‚ŒãŸå€¤ã‚’å–å¾—
            selected_option = select.find('option', selected=True)
            if not selected_option:
                # data-selectedå±æ€§ã‚‚ãƒã‚§ãƒƒã‚¯
                selected_value = select.get('data-selected', '')
            else:
                selected_value = selected_option.get('value', '')
            
            return FilterParameter(
                name=self._get_filter_name_from_id(select_id, data_filter),
                id=select_id,
                data_filter=data_filter,
                options=options,
                selected_value=selected_value,
                data_url=data_url,
                data_url_selected=data_url_selected
            )
            
        except Exception as e:
            logger.warning(f"selectã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆè§£æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _get_filter_name_from_id(self, element_id: str, data_filter: str = '') -> str:
        """element IDã¾ãŸã¯data-filterã‹ã‚‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åã‚’æ¨å®š"""
        # ID â†’ åå‰ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ‹¡å¼µç‰ˆï¼‰
        id_to_name = {
            'fs_exch': 'Exchange (å–å¼•æ‰€)',
            'fs_idx': 'Index (æŒ‡æ•°)',
            'fs_sec': 'Sector (ã‚»ã‚¯ã‚¿ãƒ¼)',
            'fs_ind': 'Industry (æ¥­ç•Œ)',
            'fs_geo': 'Country (å›½)',
            'fs_cap': 'Market Cap (æ™‚ä¾¡ç·é¡)',
            'fs_sh_price': 'Price (æ ªä¾¡)',
            'fs_fa_div': 'Dividend Yield (é…å½“åˆ©å›ã‚Š)',
            'fs_fa_epsrev': 'EPS/Revenue Revision (EPSãƒ»å£²ä¸Šæ”¹è¨‚)',
            'fs_sh_short': 'Short Float (ã‚·ãƒ§ãƒ¼ãƒˆæ¯”ç‡)',
            'fs_an_recom': 'Analyst Recommendation (ã‚¢ãƒŠãƒªã‚¹ãƒˆæ¨å¥¨)',
            'fs_sh_opt': 'Option/Short (ã‚ªãƒ—ã‚·ãƒ§ãƒ³/ã‚·ãƒ§ãƒ¼ãƒˆ)',
            'fs_earningsdate': 'Earnings Date (æ±ºç®—æ—¥)',
            'fs_ipodate': 'IPO Date (IPOæ—¥)',
            'fs_sh_avgvol': 'Average Volume (å¹³å‡å‡ºæ¥é«˜)',
            'fs_sh_relvol': 'Relative Volume (ç›¸å¯¾å‡ºæ¥é«˜)',
            'fs_sh_curvol': 'Current Volume (å½“æ—¥å‡ºæ¥é«˜)',
            'fs_sh_trades': 'Trades (å–å¼•å›æ•°)',
            'fs_sh_outstanding': 'Shares Outstanding (ç™ºè¡Œæ¸ˆæ ªå¼æ•°)',
            'fs_sh_float': 'Float (æµ®å‹•æ ªæ•°)',
            'fs_ta_perf2': 'Performance 2 (ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ 2)',
            'fs_ta_perf': 'Performance (ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹)',
            'fs_targetprice': 'Target Price (ç›®æ¨™æ ªä¾¡)',
            'fs_ta_highlow52w': '52W High/Low (52é€±é«˜å€¤/å®‰å€¤)',
            'fs_ta_sma20': 'SMA20 (20æ—¥ç§»å‹•å¹³å‡)',
            'fs_ta_sma50': 'SMA50 (50æ—¥ç§»å‹•å¹³å‡)',
            'fs_ta_sma200': 'SMA200 (200æ—¥ç§»å‹•å¹³å‡)',
            'fs_ta_change': 'Change (å¤‰åŒ–)',
            'fs_ta_volume': 'Volume (å‡ºæ¥é«˜)',
            'fs_fa_pe': 'P/E Ratio (PER)',
            'fs_fa_peg': 'PEG Ratio (PEGæ¯”)',
            'fs_fa_ps': 'P/S Ratio (PSR)',
            'fs_fa_pb': 'P/B Ratio (PBR)',
            'fs_fa_pc': 'P/C Ratio (PCR)',
            'fs_fa_pfcf': 'P/FCF Ratio (P/FCFæ¯”)',
            'fs_fa_epsyoy': 'EPS Growth YoY (EPSå‰å¹´æ¯”æˆé•·)',
            'fs_fa_epsqoq': 'EPS Growth QoQ (EPSå‰å››åŠæœŸæ¯”æˆé•·)',
            'fs_fa_salesyoy': 'Sales Growth YoY (å£²ä¸Šå‰å¹´æ¯”æˆé•·)',
            'fs_fa_salesqoq': 'Sales Growth QoQ (å£²ä¸Šå‰å››åŠæœŸæ¯”æˆé•·)',
            'fs_fa_eps5y': 'EPS Growth 5Y (EPS5å¹´æˆé•·)',
            'fs_fa_sales5y': 'Sales Growth 5Y (å£²ä¸Š5å¹´æˆé•·)',
            'fs_fa_roe': 'ROE',
            'fs_fa_roa': 'ROA',
            'fs_fa_roi': 'ROI',
            'fs_fa_curratio': 'Current Ratio (æµå‹•æ¯”ç‡)',
            'fs_fa_quickratio': 'Quick Ratio (å½“åº§æ¯”ç‡)',
            'fs_fa_ltdebt': 'LT Debt/Eq (é•·æœŸè² å‚µæ¯”ç‡)',
            'fs_fa_debt': 'Debt/Eq (è² å‚µæ¯”ç‡)',
            'fs_fa_grossmargin': 'Gross Margin (å£²ä¸Šç·åˆ©ç›Šç‡)',
            'fs_fa_opermargin': 'Operating Margin (å–¶æ¥­åˆ©ç›Šç‡)',
            'fs_fa_profitmargin': 'Profit Margin (ç´”åˆ©ç›Šç‡)',
            'fs_fa_payout': 'Payout Ratio (é…å½“æ€§å‘)',
            'fs_fa_insiderown': 'Insider Own (ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ‰€æœ‰)',
            'fs_fa_insidertrans': 'Insider Trans (ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼å–å¼•)',
            'fs_fa_insthold': 'Inst Hold (æ©Ÿé–¢æŠ•è³‡å®¶ä¿æœ‰)',
            'fs_fa_insttrans': 'Inst Trans (æ©Ÿé–¢æŠ•è³‡å®¶å–å¼•)',
        }
        
        # data-filter â†’ åå‰ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        filter_to_name = {
            'exch': 'Exchange (å–å¼•æ‰€)',
            'idx': 'Index (æŒ‡æ•°)',
            'sec': 'Sector (ã‚»ã‚¯ã‚¿ãƒ¼)',
            'ind': 'Industry (æ¥­ç•Œ)',
            'geo': 'Country (å›½)',
            'cap': 'Market Cap (æ™‚ä¾¡ç·é¡)',
            'sh_price': 'Price (æ ªä¾¡)',
            'fa_div': 'Dividend Yield (é…å½“åˆ©å›ã‚Š)',
            'fa_epsrev': 'EPS/Revenue Revision (EPSãƒ»å£²ä¸Šæ”¹è¨‚)',
            'sh_short': 'Short Float (ã‚·ãƒ§ãƒ¼ãƒˆæ¯”ç‡)',
            'an_recom': 'Analyst Recommendation (ã‚¢ãƒŠãƒªã‚¹ãƒˆæ¨å¥¨)',
            'sh_opt': 'Option/Short (ã‚ªãƒ—ã‚·ãƒ§ãƒ³/ã‚·ãƒ§ãƒ¼ãƒˆ)',
            'earningsdate': 'Earnings Date (æ±ºç®—æ—¥)',
            'ipodate': 'IPO Date (IPOæ—¥)',
            'sh_avgvol': 'Average Volume (å¹³å‡å‡ºæ¥é«˜)',
            'sh_relvol': 'Relative Volume (ç›¸å¯¾å‡ºæ¥é«˜)',
            'sh_curvol': 'Current Volume (å½“æ—¥å‡ºæ¥é«˜)',
            'sh_trades': 'Trades (å–å¼•å›æ•°)',
            'sh_outstanding': 'Shares Outstanding (ç™ºè¡Œæ¸ˆæ ªå¼æ•°)',
            'sh_float': 'Float (æµ®å‹•æ ªæ•°)',
            'ta_perf2': 'Performance 2 (ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ 2)',
            'ta_perf': 'Performance (ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹)',
            'targetprice': 'Target Price (ç›®æ¨™æ ªä¾¡)',
        }
        
        # IDã‹ã‚‰åå‰ã‚’å–å¾—
        if element_id in id_to_name:
            return id_to_name[element_id]
        
        # data-filterã‹ã‚‰åå‰ã‚’å–å¾—
        if data_filter in filter_to_name:
            return filter_to_name[data_filter]
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if element_id:
            return element_id.replace('fs_', '').replace('_', ' ').title()
        elif data_filter:
            return data_filter.replace('_', ' ').title()
        else:
            return 'Unknown Filter'
    
    def categorize_filters(self, filters: List[FilterParameter]) -> Dict[str, List[FilterParameter]]:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã«åˆ†é¡"""
        categories = {
            'åŸºæœ¬æƒ…å ±ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': [],
            'æ ªä¾¡ãƒ»æ™‚ä¾¡ç·é¡ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': [],
            'é…å½“ãƒ»è²¡å‹™ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': [],
            'ã‚¢ãƒŠãƒªã‚¹ãƒˆãƒ»æ¨å¥¨ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': [],
            'æ—¥ä»˜ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': [],
            'å‡ºæ¥é«˜ãƒ»å–å¼•ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': [],
            'æ ªå¼ç™ºè¡Œç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': [],
            'ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': [],
            'ãã®ä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': []
        }
        
        category_keywords = {
            'åŸºæœ¬æƒ…å ±ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': ['exchange', 'index', 'sector', 'industry', 'country', 'exch', 'idx', 'sec', 'ind', 'geo'],
            'æ ªä¾¡ãƒ»æ™‚ä¾¡ç·é¡ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': ['market cap', 'price', 'target price', 'cap', 'sh_price', 'targetprice'],
            'é…å½“ãƒ»è²¡å‹™ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': ['dividend', 'eps', 'revenue', 'short', 'pe', 'pb', 'ps', 'roe', 'roa', 'margin', 'debt', 'fa_'],
            'ã‚¢ãƒŠãƒªã‚¹ãƒˆãƒ»æ¨å¥¨ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': ['analyst', 'recommendation', 'an_recom'],
            'æ—¥ä»˜ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': ['earnings date', 'ipo date', 'earningsdate', 'ipodate'],
            'å‡ºæ¥é«˜ãƒ»å–å¼•ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': ['volume', 'trades', 'sh_avgvol', 'sh_relvol', 'sh_curvol', 'sh_trades'],
            'æ ªå¼ç™ºè¡Œç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': ['shares', 'float', 'outstanding', 'sh_outstanding', 'sh_float'],
            'ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼': ['performance', 'sma', 'change', 'high', 'low', 'ta_'],
        }
        
        for filter_param in filters:
            assigned = False
            search_text = f"{filter_param.name.lower()} {filter_param.data_filter.lower()}"
            
            for category, keywords in category_keywords.items():
                if any(keyword in search_text for keyword in keywords):
                    categories[category].append(filter_param)
                    assigned = True
                    break
            
            if not assigned:
                categories['ãã®ä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼'].append(filter_param)
        
        return categories
    
    def export_to_markdown(self, filters: List[FilterParameter], output_file: str = None):
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æƒ…å ±ã‚’Markdownå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if output_file is None:
            output_file = f"finviz_filters_analysis_{self.html_file_path.stem}.md"
        
        try:
            categorized_filters = self.categorize_filters(filters)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("# Finviz ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼è©³ç´°ä¸€è¦§\n\n")
                f.write(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«: `{self.html_file_path.name}`\n")
                f.write(f"è§£ææ—¥æ™‚: {os.path.getctime(self.html_file_path)}\n\n")
                f.write("ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€Finvizã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã§ä½¿ç”¨ã§ãã‚‹å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¨ãã®å–å¾—å¯èƒ½ãªå€¤ã‚’è©³ç´°ã«è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚\n\n")
                
                for category, category_filters in categorized_filters.items():
                    if not category_filters:
                        continue
                        
                    f.write(f"## {category}\n\n")
                    
                    for filter_param in category_filters:
                        f.write(f"### {filter_param.name} - `{filter_param.data_filter}`\n")
                        
                        if filter_param.selected_value:
                            f.write(f"**ç¾åœ¨é¸æŠå€¤**: `{filter_param.selected_value}`\n\n")
                        
                        if filter_param.options:
                            # ã‚°ãƒ«ãƒ¼ãƒ—ãŒã‚ã‚‹å ´åˆã¨ãªã„å ´åˆã§è¡¨ç¤ºã‚’åˆ†ã‘ã‚‹
                            has_groups = any(option.group for option in filter_param.options)
                            
                            if has_groups:
                                f.write("| å€¤ | èª¬æ˜ | ã‚°ãƒ«ãƒ¼ãƒ— |\n")
                                f.write("|---|---|---|\n")
                                
                                for option in filter_param.options:
                                    group = option.group or "-"
                                    f.write(f"| `{option.value}` | {option.label} | {group} |\n")
                            else:
                                f.write("| å€¤ | èª¬æ˜ |\n")
                                f.write("|---|---|\n")
                                
                                for option in filter_param.options:
                                    f.write(f"| `{option.value}` | {option.label} |\n")
                            
                            f.write("\n")
                        
                        # data-urlæƒ…å ±ãŒã‚ã‚Œã°è¿½åŠ 
                        if filter_param.data_url:
                            f.write(f"**Data URL**: `{filter_param.data_url}`\n\n")
                        
                        f.write("\n")
                
                # ä½¿ç”¨æ–¹æ³•ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                f.write("## ä½¿ç”¨æ–¹æ³•\n\n")
                f.write("ã“ã‚Œã‚‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¯ã€Finvizã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã§URLã®ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚\n\n")
                f.write("### ä¾‹:\n")
                f.write("```\n")
                f.write("https://finviz.com/screener.ashx?v=111&f=cap_large,sec_technology,ta_perf_1w_o5\n")
                f.write("```\n\n")
                f.write("### è¤‡æ•°æ¡ä»¶ã®çµ„ã¿åˆã‚ã›:\n")
                f.write("- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¤‡æ•°æŒ‡å®šå¯èƒ½\n")
                f.write("- ç•°ãªã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¯ AND æ¡ä»¶ã§çµåˆ\n")
                f.write("- åŒä¸€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®è¤‡æ•°å€¤ã¯ OR æ¡ä»¶ã§çµåˆï¼ˆä¸€éƒ¨ä¾‹å¤–ã‚ã‚Šï¼‰\n\n")
            
            logger.info(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æƒ…å ±ã‚’ {output_file} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")
            
        except Exception as e:
            logger.error(f"Markdownå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
    
    def export_to_json(self, filters: List[FilterParameter], output_file: str = None):
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æƒ…å ±ã‚’JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if output_file is None:
            output_file = f"finviz_filters_analysis_{self.html_file_path.stem}.json"
        
        try:
            filter_data = {
                'source_file': str(self.html_file_path),
                'total_filters': len(filters),
                'filters': []
            }
            
            for filter_param in filters:
                options_data = []
                for option in filter_param.options:
                    options_data.append({
                        'value': option.value,
                        'label': option.label,
                        'group': option.group
                    })
                
                filter_info = {
                    'name': filter_param.name,
                    'id': filter_param.id,
                    'data_filter': filter_param.data_filter,
                    'selected_value': filter_param.selected_value,
                    'options_count': len(options_data),
                    'options': options_data
                }
                
                # data-urlæƒ…å ±ãŒã‚ã‚Œã°è¿½åŠ 
                if filter_param.data_url:
                    filter_info['data_url'] = filter_param.data_url
                if filter_param.data_url_selected:
                    filter_info['data_url_selected'] = filter_param.data_url_selected
                
                filter_data['filters'].append(filter_info)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(filter_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æƒ…å ±ã‚’ {output_file} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")
            
        except Exception as e:
            logger.error(f"JSONå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
    
    def print_summary(self, filters: List[FilterParameter]):
        """è§£æçµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ“Š Finviz ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è§£æçµæœã‚µãƒãƒªãƒ¼")
        print("="*60)
        
        categorized = self.categorize_filters(filters)
        
        print(f"ğŸ“„ ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«: {self.html_file_path.name}")
        print(f"ğŸ”¢ ç·ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ•°: {len(filters)}")
        print(f"ğŸ“‚ ã‚«ãƒ†ã‚´ãƒªãƒ¼æ•°: {len([c for c, f in categorized.items() if f])}")
        
        print("\nğŸ“‹ ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥çµ±è¨ˆ:")
        for category, category_filters in categorized.items():
            if category_filters:
                print(f"  ğŸ“Š {category}: {len(category_filters)}å€‹")
        
        # Top 5 ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æ•°é †ï¼‰
        top_filters = sorted(filters, key=lambda x: len(x.options), reverse=True)[:5]
        print(f"\nğŸ” ã‚ªãƒ—ã‚·ãƒ§ãƒ³æ•°ä¸Šä½5ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼:")
        for i, filter_param in enumerate(top_filters, 1):
            print(f"  {i}. {filter_param.name}: {len(filter_param.options)}å€‹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        print("\n" + "="*60)
    
    def analyze(self, export_format: str = 'both'):
        """å®Œå…¨ãªè§£æã‚’å®Ÿè¡Œ"""
        try:
            logger.info("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è§£æã‚’é–‹å§‹ã—ã¾ã™...")
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æŠ½å‡º
            filters = self.extract_filter_parameters()
            
            if not filters:
                logger.error("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return False
            
            # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
            self.print_summary(filters)
            
            # çµæœå‡ºåŠ›
            if export_format in ['markdown', 'both']:
                self.export_to_markdown(filters)
            
            if export_format in ['json', 'both']:
                self.export_to_json(filters)
            
            return True
            
        except Exception as e:
            logger.error(f"è§£æå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='Finviz HTMLãƒ•ã‚¡ã‚¤ãƒ«è§£æãƒ„ãƒ¼ãƒ«',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python finviz_html_analyzer.py finviz_screen_page.html
  python finviz_html_analyzer.py finviz_screen_page.html --format json
  python finviz_html_analyzer.py finviz_screen_page.html --format markdown
        """
    )
    
    parser.add_argument(
        'html_file',
        nargs='?',
        default='finviz_screen_page.html',
        help='è§£æã™ã‚‹HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: finviz_screen_page.html)'
    )
    
    parser.add_argument(
        '--format', '-f',
        choices=['markdown', 'json', 'both'],
        default='both',
        help='å‡ºåŠ›å½¢å¼ã‚’æŒ‡å®š (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: both)'
    )
    
    args = parser.parse_args()
    
    print("ğŸ” Finviz HTML ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è§£æãƒ„ãƒ¼ãƒ«")
    print("="*50)
    
    try:
        # è§£æå™¨åˆæœŸåŒ–
        analyzer = FinvizHTMLAnalyzer(args.html_file)
        
        # è§£æå®Ÿè¡Œ
        success = analyzer.analyze(export_format=args.format)
        
        if success:
            print("\nâœ… è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            stem = Path(args.html_file).stem
            
            if args.format in ['markdown', 'both']:
                md_file = f"finviz_filters_analysis_{stem}.md"
                if os.path.exists(md_file):
                    size = os.path.getsize(md_file) / 1024
                    print(f"ğŸ“„ {md_file} ({size:.1f} KB)")
            
            if args.format in ['json', 'both']:
                json_file = f"finviz_filters_analysis_{stem}.json"
                if os.path.exists(json_file):
                    size = os.path.getsize(json_file) / 1024
                    print(f"ğŸ“Š {json_file} ({size:.1f} KB)")
        else:
            print("\nâŒ è§£æã«å¤±æ•—ã—ã¾ã—ãŸ")
            return 1
            
    except FileNotFoundError as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 